# raw_docs = [{'keyword': 'ChatGLM3-6b',
#         'formatted_videos': '"热门视频标题1.【保姆级教程】6小时掌握开源大模型本地部署到微调，从硬件指南到ChatGLM3-6B模型部署微调实战｜逐帧详解｜直达技术底层 \\n热门视频标题2.【官方教程】ChatGLM3-6B 部署和微调（Function Call、Code Interpreter、Agent） \\n热门视频标题3.4060Ti 16G显卡运行chatglm3-6b-32k模型效果 \\n热门视频标题4.低配置部署 ChatGLM3-6B | 智谱 × 魔搭社区 \\n热门视频标题5.部署微调ChatGlm3-6B大模型【小白0到1】 \\n热门视频标题6.ChatGLM3-6B 对比 Qwen-14B，到底谁更强？ \\n热门视频标题7.【保姆级教程】使用ChatGLM3-6B＋oneAPI＋Fastgpt＋LLaMA-Factory实现本地大模型微调＋知识库＋接口管理 \\n热门视频标题8.30分钟学会运行ChatGLM3-6B模型的P-Turning V2高效微调及全量微调代码 \\n热门视频标题9.ChatGLM3-6B，启动！ \\n热门视频标题10.【大模型微调】ChatGLM3-6b大模型微调 | 基于开源的大模型的微调 | 使用自己的数据集来微调大模型 | 垂直领域大模型 | lora微调大模型 \\n热门视频标题11.【开源】ChatGLM3-6B发布了！大升级！轻松接入现有项目接口，支持实时上传文档-Chatglm3-6B、大语言模型、模型微调、模型部署、人工智能、大模型 \\n热门视频标题12.大模型chatglm3-6b之开外挂 \\n热门视频标题13.在Windows 系统上部署运行ChatGLM3-6B的第一步，正确理解项目文件的作用及下载方式 \\n热门视频标题14.手把手教你低配置部署ChatGLM3-6b \\n热门视频标题15.单机多卡环境下轻松部署ChatGLM3 -6B模型，合理应用与灵活管理GPU资源 \\n热门视频标题16.5种运行ChatGLM3-6B模型的方式！大模型本地部署必备|手把手领学，效率指数提升！ \\n热门视频标题17.chatglm3-6b部署教程（胎教版） \\n热门视频标题18.【保姆级教程】6小时掌握开源大模型本地部署到微调，从硬件指南到ChatGLM3-6B模型部署微调实战，这应该是B站最好的大模型教程了！ \\n热门视频标题19.AI大模型-实战QLoRA微调ChatGLM3-6B \\n热门视频标题20.【实践篇】ChatGLM3-6B的安装部署、微调、训练智能客服 \\n"',
#         'data_to_write': '[["video", "木羽Cheney", "职业职场", "http://www.bilibili.com/video/av241845815", "【保姆级教程】6小时掌握开源大模型本地部署到微调，从硬件指南到ChatGLM3-6B模型部署微调实战｜逐帧详解｜直达技术底层", "公开课节选自付费课程《大模型技术实战课》，2024最新版2期课程现已上线！6大主流大模型+14项大模型工具+5大热门方向企业级实战项目，零基础直达大模型企业级应用！【付费课程信息】添加+🌏：littlecat_1207，回复“大模型”详询哦～", 144443, 1451, 9906, "模型, 人工智能, AI, 部署, 微调, 深度学习, OpenAI, 本地部署, 大语言模型 (LLM), ChatGLM3", 0, ["666", "666", "666", "666", "666", "666\\n国庆期间看了多个相关课程，本课程是B站少有的大模型本地部署课程，干货满满。UP主辛苦", "简单易懂，讲的很不错，赞赞赞~\xa0 \xa0同求课件", "666", "没太懂，需要再看看", "666", "up主，我想问一下我的显卡rtx3060我的是2021年款的拯救者R9000p，我有门课需要配置ChatGLM3-6b，我能配吗", "666", "求课件", "请问启动Ubuntu 一直黑屏是什么原因", "666", "666", "求课件", "大佬很厉害，求课件", "请问一直显示找不到requirements是怎么回事", "求课件", "666", "666", "666", "666", "up 你好 对于openai api风格的部署有些疑问，可以私我一下吗，感谢", "请问微调的话，4090单卡可以么？", "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (mpi4py)微调的时候遇到了这个问题", "我搞出来了，一方面，执行的是那个server文件，另一方面，api_server,py不只需要chatglm的模型文件，还需要一个向量模型文件，下载好后，加个路径就好；如果梯子稳定的话，等个五六分钟下载好能直接运行，没有梯子应该得先下载向量模型大约5个G，bge的，或者m3e的都行", "UP，chatglm3-6b部署后，想调用openAI的接口，open_api_server.py改过模型地址后仍然跑不起来，方便的话，可以交流下吗？", "666，讲的特别好，求课件。", "666", "666", "666", "666", "666", "Ubuntu2204好还是2404好啊？", "666", "666", "666求课件", "666", "666", "666 大佬麻烦发下课件", "666", "666[支持]，帮忙发一下资料谢谢！", "666！简明易懂，楼主必火！", "666", "太6了，UP求课件[喜欢]", "大哥，静等资料", "666", "是在申请的阿里云pai云主机上安装windows和ubantu双系统？", "666", "讲的啥也不是", "良心主播", "666", "666", "666，学习起来，求课件", "666", "666", "666", "666", "666", "保姆级教程 很好", "666", "干活满满", "大佬看着很年轻啊  挺有专家范", "666", "666", "想请教一下，显卡分布在多个主机上，怎么集群部署", "666", "666", "UP主这个视频录的好哇，好就好在画面稳定，不像其他UP主，画面高频切换，鼠标移来移去，看的头昏眼花。点赞一个", "666", "这个课程是B站少有的大模型本地部署课程，干货满满。UP主辛苦", "为什么一到安装requirement.txt就会失败啊 救救孩子", "666", "666", "666", "666求课件", "666", "666", "博主的网名是不是名字里的字里 各取了一部分组成的", "666", "666", "慕名而来[给心心]", "666", "AttributeError: &#39;GenerationConfig&#39; object has no attribute &#39;_eos_token_tensor&#39;咋解决？", "666，up主讲的很全面，求课件", "python cli_demo.py 报错：UnicodeDecodeError: &#39;ascii&#39; codec can&#39;t decode byte 0xe6 in position 0: ordinal not in range(128)，有人遇到吗，用的阿里云", "666", "666", "up主   ipython-kernel-install: error: unrecognized arguments: --displayname=Python(chatglm3_test)\\n\\n这个怎么办，网上找不到方法", "实战课程啥时候出[脱单doge]", "666，up主讲的很全面，求课件", "666", "666", "666", "666", "安装依赖出问题怎么办呀～换了个电脑也出问题，不知道怎么解决", "666", "666，求课件", "666", "666", "666! UPUP, 求课件", "666", "666", "666", "模型正常加载，输入stop会正常退出，但是输入其他内容就报错[灵魂出窍]", "666", "666", "666! UPUP, 求课件", "666! UPUP, 求课件", "666", "666，求课件", "666，求课件", "在服务器上运行web, demo,是不是无法在自己的电脑上运行，我打开输入后会报错", "666！up主讲的真棒，全是干货，辛苦up主分享一下课件，谢谢[呲牙]", "666", "666，已一键三连，求课件！", "求个课件", "666", "666！up主讲的真棒，全是干货，麻烦分享一下课件，谢谢！", "666", "666", "3090不是停产了很久了吗？或者都是矿卡，现在哪里可以买到靠谱的？求推荐", "已三连，求个课件，感谢UP主[支持]", "一直照着稿子念么", "为啥后面的几节都是绿屏", "666", "666", "666", "666 大佬，已三连求课件", "三连求课件[脱单doge]", "666", "大佬求个课件[打call][打call][打call]", "666", "666", "666", "666，求资料[抱拳]", "666，已三连，求个课件，感谢UP主[支持]", "666", "666", "启动到这一步，对话时报错[大哭]", "感谢老师，讲的真的很详细！！！", "666 up主 发个课件  球球了[保佑]", "可以使用虚拟机做吗", "666，非常好的课程，真的是保姆级教程，求个课件，感谢up主", "up主我也是这个问题 pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple报错显示Getting requirements to build wheel did not run successfully.\\nexit code: 1怎么解决呀", "666", "666", "666，非常好的课程，真的是保姆级教程，求个课件，感谢up主。", "666", "666求课件", "666", "666，求个课件，感谢大佬", "666", "Getting requirements to build wheel did not run successfully.\\nexit code: 1\\n叨扰了up，在下载requirements.txt遇见了这样的问题，请问这怎么解决[大哭]，好人一生平安", "666", "666", "666求课件！", "一个GPU对应2-4个CPU核数就可以了。请问前面这句话如何理解呢？一般的CPU比如有24核，36核，48核，64核等，一个是一个GPU买一个24核的CPU就远远的满足要求了？\\n拿4090来举例呢？", "已三连 666", "666，求资料，谢谢", "666", "666", "666", "666，感谢up，非常实用[支持]", "666求课件", "666", "666求课件", "666", "666", "666", "666，真的是保姆级教程，求个课件，感谢up主。", "666", "大佬，求个课件复习", "666", "求课件，另外up主能否预估一下整套计算机满足本地部署单精glm3的大概预算是多少", "本地部署单精chatglm3-6b实现微调和推理，购买计算机所有硬件预算多少钱合适", "如果大模型只是按照匹配自然语言功能是否都显卡就没有太大要求了", "请问 常见的可本地部署的开源大模型类型有好多，最后选定ChatGLM3的初衷是什么？", "666", "666 滴滴滴 up主讲的太好啦", "666，求课件", "想问一下，为啥没有教在云服务器上的使用呀", "666", "在远程服务器部署的话ubuntu要怎么装上去呢", "算计平台[doge]", "666     三连了  求资料", "666求课件，up主，", "666", "已经三联，想要课件，可以吗，\\n，谢谢", "666", "666", "除了有点啰嗦其他还挺好", "666", "666求课件，up主，", "666", "666", "666 滴滴", "666"], "2024-01-27 19:35:51"], ["video", "ChatGLM", "计算机技术", "http://www.bilibili.com/video/av747967526", "【官方教程】ChatGLM3-6B 部署和微调（Function Call、Code Interpreter、Agent）", "ChatGLM3 技术文档：https://zhipu-ai.feishu.cn/wiki/YInmwPmyii67VRkzU3BchPNzncg\\n\\n模型仓库：https://github.com/THUDM/ChatGLM3\\n\\n模型下载：\\nHF：https://huggingface.co/THUDM\\n魔搭：https://modelscope.cn/models/ZhipuAI\\n\\n文件下载：https://pan.baidu.com/s/14NtD9A3Ls3VkuIPy8Iar8Q?pwd=na5c", 102069, 182, 5950, "人工智能, 清华大学, 微调, 大模型, agent, chatglm, 智谱AI", 0, ["mac下能安装vllm吗？", "up，你好，设备系统都满足条件，但是每次推理都出现这个错误，此时temperature=0.01；temperature=0.8的时候会有部分回复，但是是乱回复的，答非所问，而且逻辑不通，回复一段时间后还是报这个错误，请问这个问题如何解决", "请问，如果我想搭建一个本地库，如果给100个人用，需要的硬件大概是什么配置啊？", "啊，找了好久才看到有人跟我差不多的问题，你解决了吗？我新手刚玩大模型，1060显卡部署上去之后一秒出1-3个汉字好慢，显存倒是占用了，GPU利用率0%， cpu 6%这样，都不知道是不是正常现象。", "fintune的preprosess预处理的代码怎么没有在github仓库里啊  就是你最后展示的复杂代码啊", "360报毒", "新手很懵b啊", "我在本地部署了chatglm3-6B的模型，在composite_demo用streamlit run运行后，选择代码解释器，输入“画一个爱心“，代码正常输出，无法执行产生图片，提示“FigureCanvasAgg is non-interactive , and thus cannot be shown”，这是什么原因？如何解决呢？不显示图片的代码能够正常执行。非常感谢", "你好，我在本地使用最新的代码示例（fine_demo这个示例)，命令行输入如下：\\npython finetune_hf.py  data/AdvertiseGen/  THUDM/chatglm3-6b  configs/lora.yaml\\n最后cmd打印出\\n“Dumping model to file cache C:\\\\Users\\\\xx\\\\AppData\\\\Local\\\\Temp\\\\jieba.cache\\nLoading model cost 0.560 seconds.\\nPrefix dict has been built successfully.”\\n但是output目录下，并没有checkpoints，是空的。我看了下finetune_hf.py源代码，savemodel方法被官方注释掉了。\\n我去除掉了注释，并在整个代码的最后一行写了trainer.save_model(output_dir=&#39;./output&#39;)。\\n再次微调后，得到报错信息：", "chatglm3的代码解释器不输出结果，是怎么回事？", "想问下，给他一个文本让他学习，能把学习效果记录下来吗，下次直接软件调用给出各种不同的问题让他反馈", "讲的不错，就是没听懂。。\\n\\n另外，音频是不是加快了一点。 后面都每怎么听清楚。\\n\\nPS。 上个字幕出来吧", "最近想部署一个客服机器人，我看了官网给的微调案列是针对一个方向的，但是在实际的使用中，肯定不会只针对这个一个小方向来微调，比如我电商客服机器人，就会有”关于发货“、”关于售后“、”关于质保“等几个方面，我现在也是可以把这些问题都罗列出来，然后进行微调，这时候就会出现，买家的问题一般都是很少的，进行切分的时候，经常会出现问题。但是我觉得这个可以根据参数才进行提高。但是我核心问题是，如果我给的训练参数问题包括”我已经下单了“、”请抓紧发货“，这时候我的回答都是”我们将尽快为您安排发货“，我的预期微调是对这些关于发货方面的问题语进行一次语言模型训练，就是会自动识别出来，我的问题是关于发货的，买家问”急急急，快发货“或者其他的，我也是知道自动回答”我们将尽快为您安排发货“，可能也是我了解的不够多，求大神可以解惑。", "我发布了一篇笔记，快来看看吧~", "我装的环境里，只能写出代码，无法看到执行结果（比如画爱心）", "大佬您好，我遇到个问题，我看微调前ChatGLM3-6B模型embedding的尺寸是65024*4096，但我按finetune_demo中指导进行LORA微调后，推理时从checkpoint处读入的模型embedding的尺寸变成了64796*4096，导致报了下标越界的错，请问这是怎么回事？", "你好请问a卡可以训练吗，或者m系列苹果芯片可以训练吗", "有多模态吗？", "@AI视频小助理 总结一下", "你这演示的算数算错了", "Setting eos_token is not supported, use the default one.\\nSetting pad_token is not supported, use the default one.\\nSetting unk_token is not supported, use the default one.最后一步这三个报错是怎么一回事啊up", "有技术支持群吗，好像都满了，这个加上langchain就能实现个人知识库概念吗", "光标指的和嘴上说的不一样，口齿也不清楚，表达也不清晰，下次能换人讲么?？？？？", "这个模型支持最大的输入字符是多少", "模型训练教程：https://www.bilibili.com/video/BV1hA411k7cC/", "需要安装一些环境，你呀倒是说要哪些啊", "你好，我电脑显卡是amd 16G的，能部署langchain+chatglm3，能运行顺畅？最好安装哪个版本？谢谢", "code interpreter应该难度还好。", "我今天又跑了一下chatglm3-6b，用了量化int4代码的方式，但是发展对话模式下有时候会输出中英文混合，up请问会解决这个问题吗？", "老师，用lora微调时候，数据格式是{&#34;context&#34;: &#34;hello&#34;, &#34;target&#34;: &#34;hi,I am ChatGLM3&#34;}，打印训练数据的预处理信息，发现context内容对应的target_id都是-100，这有什么讲究吗？有可以学习的一些知识链接吗？", "请问微调的代码开源了吗？孩子的毕设就靠他了[给心心]", "请问微调chatglm3，需要多大的显卡？", "[脸红][脸红][脸红]可以再出一个windows环境跟linux环境的教程嘛", "想问下支持API不，想要用VOXTA调用然后进行语音对话", "问下，是否有针对chatglm3的数据集制作工具", "画爱心，代码生成完整，但无法在页面显示", "可以用这个模型的int4 来翻译中英文。", "还在宿舍写报告，但是已经想好第二天回家怎么折腾家里的电脑跑AI了[doge][doge][doge]", "大佬  我amd显卡怎么跑？", "音频不同步，下次录制的时候，建议先测一下", "这个模型6b的普通版和32k的版本在问他23的阶乘时，会进入一个回复的死循环。。。。", "请问一下chatglm3的数学能力是通过训练什么数据得到的呢？目前有开源数学题数据吗？", "求助up，全参数微调的硬件配置有什么要求呀[大哭]", "可以认知学习心电图吗", "请问下大佬，怎么写prompt训练glm3让其学会新function call使用，或者怎么微调让glm3能学会使用新的function call", "我们微调了chatglm3-6b-base，但是我们把微调参数加上他没输出了，为什么啊", "厉害的，希望能开源参数更大的模型，我这两张3090已经迫不及待想试试了", "Code Interpreter总是输出一段就停止是什么原因导致的，Output length设置的很大，Chat模式下没有问题", "大家好  这东西一定要独立显卡才能跑吗  ？集成显卡可以不？   如果没有独立显卡能不能自动切换成 CPU 跑", "我下载了一个巫师三的模型结果问周树人和鲁迅还是出错了不知道这个怎么样", "请问up是通过什么工具来部署chatglm的呢", "想问下大佬，我想用glm3做一个物理方面的垂直领域模型，我加入很多专业词汇以及化学式子扩表是否有助于我在物理领域表现得更好呢？", "一台低配保时捷", "请问部署需要什么环境啊？", "你们有没有打算搞个多模态的13b的？", "windows可以部署吗", "a卡可以跑吗[初音未来_问号]", "作者您好，我在训练时候，报错Distributed package doesn&#39;t have NCCL built in", "对chatglm3的tools的微调，会影响codeinterpreter吗？是否可以通过微调，使codeinterpreter具备生成调用企业内部tool代码的能力\\n@ChatGLM", "对chatglm3的tools的微调，会影响codeinterpreter吗？是否可以通过微调，使codeinterpreter生成调用企业内部tool代码的能力", "up你好，我把所有文件和模型都下载下来然后运行webdemo运行不出来，是我的电脑跑不动吗，cpur7-6800h，显卡3050ti，以下是输出内容：Loading checkpoint shards: 100%|██████████| 7/7 【00:47&lt;00:00,  6.74s/it】\\n\\n进程已结束,退出代码-1073741819 (0xC0000005)", "为什么我的画不了爱心，椭圆，三角形？？？", "这两天测试了一下, 也把官方提供的几个demo研究了一下, 总体来说确实比glm2好许多, 也比之前用过的baichuan, yi 6b好. 但作为生产工具还是差了太多. 不知道什么时候蒸馏过的小模型也能达到100b参数模型的效果.", "老师您好，我想学习一下如何自己用代码搭建一个使用模型的webui，已经在学gradio了，但是不知道调用模型的方法从何学起，可以请老师分享一个学习路径吗", "遥遥领先！", "@ChatGLM 看私信", "我只有6g显存怎么办啊", "大佬，请问想要微调的话，用两张Tesla P40显卡可以吗", "想问下大家在用自己的数据微调chatGLM3-6B的时候，有没有遇到过它说到一半就不说的情况", "GLM3-6B的Code Interpreter，只输出代码，不运行，是因为什么", "不知道最关键的自然语言理解能力怎么样。", "我比较好奇，按照现在最新的论文，是不是参数扩大到30b，然后压缩到4bit性价比最高", "win10 +3090部署完之后推理挺快的，而且明显能看到GPU利用率，但是换到winserver 2012 + 3090 部署完之后，模型是加到显存里面了。但是推理的时候GPU利用率一直是1%几乎不动，cpu倒是跑的冒火，可能是什么原因", "有没有docker的部署教程", "请问微调后用数据集验证的代码怎么实现？", "我比较好奇的是小模型的上下文token能达到多少？[笑哭]", "能像绘画SD那样方便就好了", "mac Pro m1 16g 能跑么，感觉只能cpu mps ，巨慢", "开源是走向强大的第一步，chatglm加油！", "up主，想问下多租户模式怎么保证会话隔离的", "请问glm3何时开放api功能？嵌入式开发太需要了", "是否可以直接用python调用api在本地来跑？类似huggingface调用", "请问1.5b在哪儿下载？家电家具行业，考虑如何能用起来", "AgentTuning的微调也可以用这个框架微调吗", "计算的那里也是有点搞,  把第一个减法当乘法了", "6b 指的是参数量还是训练数据量呢？", "微调的工具在哪儿", "ChatGLM-6B和ChatGLM-130B这两个有什么区别呢？", "能聊色嗎?", "4090能训练微调吗", "请问chatglm3为什么没有类似chatglm2的do-predict批量验证fineting模型准召率的程序了，要验证自己的模型准确率怎么实现？", "你是北京智谱？", "作者你好，安装了jupyternotebook之后代码解释器还是不能显示图形（画爱心），请问是需要什么步骤？", "我看那个tool_registry, 比较纳闷GLM模型是如何识别temp_C是温度的？就是将json串中的“{&#39;current_condition&#39;: {&#39;temp_C&#39;: &#39;5&#39;, ”，解释成“气温为5摄氏度”", "请问单轮对话的微调是不是只支持json格式了？记得2好像可以直接支持csv格式的。", "up你好，我现在做的课题中有一个部分需要使用到一个文本分类的模型进行预处理，但是数据集的搜集很难，chatglm处理这个问题很方便，请问可以将chatglm用于学术研究吗🥹", "如何可以在a卡下跑啊，没n卡", "这个好像可以多卡部署，有没有人试过多张p104之类的运行，效果怎么样？", "老师您好，\\n请教个问题：关于用CI调python解析器画图这个操作是不是会存在图像不显示的情况，我看评论也有朋友遇到这个问题。有得解决吗", "请问有没有关于微调时候的各种参数对应的说明？", "是不是要勾了那个’run on save‘，每次对话的历史才能保留下来下次继续能续上呀？", "能写故事嘛？", "感觉讲的稀里糊涂的", "怎么用代码调用呢", "作者您好，想学习学习ChatGLM-6B怎么外挂数据库", "为啥说工具调用返回的是Python代码块而不是jons？试了一下返回的就是json格式啊?", "10B以上有更好的吗", "作者大大可以回答一下私信那几个问题咩～百思不得其解[笑哭]", "AI的应用在某方面是一种阴谋，就是让更多天真的人相信只要有AI就可以享受人生了。这道理就好像彩票行业一样，很多人深信只要花几元钱就有机会赚几个亿的奖金，但是有几个人能赚到彩票的奖金呢？AI最终是让优秀的人更加优秀，而贫穷的人更加贫穷，从而让社会更好的风华，让天真的人放弃学习和努力的权利。历朝历代都会出现这种情况，农民 初期都是有土地的，但是后来受不了诱惑就把自己的土地转卖了，然后几年不到就被市场的规律给洗劫一空，最后只能沦为别人的生产工具。", "请问有什么关于ChatGLM的技术交流群吗", "今天尝试写AE动画表达式，写出来的都无法使用[大哭]", "效果惊人的好 可以int4 int8 不量化在gpu或者cpu上跑。就是量化以后智商直线下降，所以我现在直接cpu跑了，gpu用了共享的内存速度跟cpu一样慢，那就干脆腾出空位运行其他的东西好了[脱单doge]", "chatglm3-6B 几个版本的区别是啥？ 一直没搞懂！", "Up主大佬，请问可以离线本地部署吗？代码方便有codegeex好用吗", "加油啊UP主，太喜欢你的模型了", "智谱什么时候升级？", "希望glm优化下推理的模型（onnx这种），静态图性能会好很多", "作者您好，GLM3支持video了嘛", "老师，如果是完整版的130B效果能达到gpt3.5么，130B需要多少显存的显卡才能部署的上呢", "我按demo视频的最开始的提示，计算的时候出现Unexpected special token: &lt;|observation|&gt;,然后chat界面也画不出爱心的形状，是什么问题，gpu是1080ti，有大佬能帮忙说下是什么问题么，万分感谢", "[喜极而泣]今天用CPU跑来起了，内存不够硬盘凑，问个你好，硬盘疯狂读写二十分钟后，终于回复了。", "大内存mac可以微调吗😯", "加油加油", "up！ai现在算我的学习工具之一，很重要，所以我就想问一个问题，智谱清言，文心一言到底哪个回答刑法学上的问题更准确[大哭]", "想了解一下跑大模型需要什么配置，台式电脑是否比笔记本更适合跑大模型？还有显卡有必要上24g的吗？16g的显卡能满足基本要求（比如喂自己的资料，参数微调）吗？希望得到解答", "为什么我在运行模型（chatglm3 6b int4）时GPU0%占用，显存占用4Gb，也就cpu动一下，利用率18%", "NBA[滑稽]", "Function可以自己开发吗", "请问一下用langchain直接对接GLM3模型，而不用GLM3自带的Funcion Call，是否可行？", "如何在mac上去搭建", "学", "只讲理论没有案例，差评", "我给个建议：既然你们是做aigc的，是不是配音就不要自己读啦？", "必须顶上去。国产大模型加油！", "这个会议哪里参加，下次我也想参加", "请教一下，自己想本地离线跑起来的话，最低需要多少配置呀。", "量化模型的性能下降的大吗", "@AI视频小助理", "想问一下用代码调用大模型生成回答为什么特别慢，回复的很慢，4060显卡", "我不是很懂，能放个gguf版本的么？", "方便将langchain对接那一段代码分享下吗", "能挂在实验室服务器上么？", "有没有 声音和画面对不上，是不是声音先于画面", "模型不翻墙在哪里下载啊？", "不知道llamacpp会不会支持这个。无卡玩家还是希望能有个关照的。（其实不完全是无卡，只是卡在实验室，调起来麻烦）", "厉害厉害，收藏了", "相当出色的模型[支持][支持]三连了！\\n顺带一问，chatglm3支持了function call，不知道up是否了解 如果想给glm3微调入一些固定的function call，需要用什么微调数据集格式和方法[脱单doge]", "可以接langchain吗", "国内唯一看好的模型[doge]", "1", "出个13b吧[打call]", "[打call]", "在我们这边的抽取任务上，glm3好像比2效果差。是不是新增的function call等导致的？", "支持效果确实非常好，今天帮我修复了一个bash脚本bug", "请问一下，tool_using目前能支持哪些tools的调用呢？", "这个需要多大的gpu?", "跑这个模型，有没性价比高的云厂家推荐啊", "这个每次启动都要联网获取认证，怎么弄，想本地离线部署", "@AI视频小助理 总结一下", "还会更新4吗，不更的话我就要用3来写论文了[doge]", "大佬们一般是在windows搭建还是在linux虚拟机上搭建模型？", "code interpreter我试了下，好像没法直接运行给出的代码，是缺什么配置吗？", "牛蛙，可以看到更多的模型融合了[doge]", "上下文对话的api应该怎么封装，能否给个都有那个功能的 demo", "鲁迅和周树人的问题还是回答不准确 刚部署完成", "【内容总结】\\n本视频是关于ChatGLM3-6B模型的部署和微调的官方教程。视频介绍了ChatGLM3-6B模型的基本特点和性能，以及模型的应用开发示例。视频演示了模型的基本对话能力、工具调用功能和代码解释器功能，并展示了模型在不同场景下的应用效果。视频还详细介绍了模型的对话格式和微调方法，以及使用Function Call、Code Interpreter和Agent等工具进行模型的部署和微调的步骤。观众评论中提到了对微调代码的期待和模型的性能等问题。\\n\\n【时间线】\\n- 00:00 - 视频介绍了ChatGLM3-6B模型的基本特点和性能。\\n- 01:34 - 演示了模型的基本对话能力，包括遵循指令和表情回答。\\n- 04:05 - 演示了模型的工具调用功能，如查询天气和绘制图案。\\n- 06:03 - 演示了模型的代码解释器功能，包括计算和几何问题的求解。\\n- 08:28 - 演示了模型的多轮对话能力，包括生成随机数、排序和求平均数等操作。\\n- 12:59 - 介绍了ChatGLM3-6B模型的对话格式和微调方法，包括特殊token和metadata的使用。\\n- 13:46 - 详细讲解了模型的对话格式和工具调用的实现方式。\\n- 20:12 - 介绍了模型通过token来表示工具调用的方法。\\n- 23:30 - 解释了推理系统如何解析模型的工具调用参数。\\n- 24:03 - 视频介绍了Function Call和Code Interpreter的使用方法，以及它们在模型部署中的作用。\\n- 26:31 - 介绍了Code Interpreter的使用，包括system prompt和assistant interpreter的概念。\\n- 29:46 - 讨论了为什么使用Python作为工具调用的语言，以及Python的表达能力和拓展性。\\n- 31:56 - 介绍了Coding Prompt的使用方法和注意事项，以及如何将对话转化为模型可接受的格式。\\n- 36:14 - 讲解\\n内容由AI自动总结, 总结内容仅供参考~ @华程朱 触发了视频总结, 触发方式是 @有趣的程序员 总结一下", "你好，請問是不是有點音畫不同步呢？", "(⊙o⊙)哇这么快的吗", "chatglm2-6b有能在手机上跑的int4了，3什么时候弄出来", "工具调用和代码执行，工具和代码是被模型的代码直接调用，运行在模型所运行的机器上吗？", "chatglm3-6b老是返回超时[大哭][大哭][大哭]，虽然最后成功启动了，能用chatglm-6b直接修改文件解决吗", "up用什么配置硬件跑的", "毕设的迁移学习对象有着落了，gpt2可以滚了[doge]", "我用chatglm3为啥总是条英文出来，比如知识库里中文上传，回答的时候就改成了upload[微笑]@ChatGLM", "eval这步看能不能和docker结合，但是这块目前我测了，chatglm对报错修改比较弱，比如报没有pip包，glm不能准确告知docker去pip install包", "有技术交流群嘛[星川铃表情包_令人头大]", "作者你好，请问有量化版本吗，绝大多数人的显卡显存在12GB以下[脱单doge]", "会偶尔有机率出现 一两段话 或一两句话 一直重复，这个是什么原因，有办法解决吗？", "也想知道官方推荐最低配置啊。 @ChatGLM 之前2的时候也贴心提供了的。", "没机会超过gpt4", "开始学习", "@AI视频小助理 详细总结一下", "啊这，这都发3了。好哥哥救救救 前两天自己写了个adapter微调chatglm2，在前向传播过程中出现 nan /inf ，我自己测了异常值出现在 chatglm 模块。该现象不论是 fp16 还是 fp32 都会产生。[藏狐]", "搞起！", "请问，能讲讲怎么给模型设定角色吗", "hugging face也上不去了…\\n反诈提示…\\n逼我clash…", "6b规模做成这样已经很棒了，网传gpt-3.5是20b[脱单doge]", "大佬，请问微调需要大概什么算力", "这个和rwkv哪个比较厉害[doge]", "有cpp部署方法吗", "您好，请问一下可以通过chatglm3模型获得一段文本的词嵌入向量吗？", "[doge]真不考虑出14b或者13b吗？", "1.5B和3B出来了嘛[呲牙][doge]", "工具调用那块的参数提取有代码样例吗", "校友打卡", "这个模型当之无愧中国第一！支持直接上传文本训练就好啦。", "[热词系列_谢谢老师]", "三连你[打call]", "好好好！用了一段时间的2代6B，感觉作为个人助手已经能发挥些作用了，希望3代能表现更好", "想问下跑ChatGLM3推荐的硬件配置是什么？"], "2023-11-01 23:02:31"], ["video", "titan909", "计算机技术", "http://www.bilibili.com/video/av493720644", "4060Ti 16G显卡运行chatglm3-6b-32k模型效果", "创建命令：docker run -d --name chatglm3 --gpus all --network host bucess/chatglm3:1 回车后会自动下载镜像并在自己的电脑上运行起来\\n\\n停止命令： docker stop chatglm3\\n\\n再次启动命令：docker start chatglm3", 25994, 16, 384, "人工智能, AI, 4060Ti16G, chatglm3", 0, ["想问一下4060laptop 8G能跑得动chatglm3-6b吗", "移动端8g显存的4060能行吗？看着显存先用好大", "电脑配置能分享一下 谢谢", "能否分享下你的电脑配置？", "运行量化模型需要多少内存？我 16g 内存加 8g 显存。载入模型时爆内存了，直接卡机。要好一会儿才能恢复好，之后倒是可以聊天了。\\n是以 int 4 量化运行。模型达到 22g。感觉内存要 32g。是不是这样？", "最近一直刷你视频   很好奇这入门卡只有选4060ti16g吗，还是说p40  p100这些大显存计算卡会更好一点。p40这些卡是不是不能跑chat RTX", "见证奇迹的时刻[呲牙]", "1060 6GB启动chatglm-6B正常，就是对话，没有任何反应，醉了。", "3060 12G能玩glm3吗？我现在还是永glm1玩玩", "这个卡能微调吗", "请问up你推荐哪个软件好", "up这壁纸叫啥", "速度和我的380元买的矿渣40HX差不多。", "请问3080 10G跑量化INT8速度能否和你的一样，我下载了懒人一键部署版，问个话回答很慢，一百个字要四五分钟", "glm3 6b base 4070够吗", "linux下有docker这种便于部署的应用真好啊", "我2张4060ti，级联PCIE，和单张比出图有优势吗", "chatgpt它字数限制经常喂的文档一次读不完，看来得升级下我的2070显卡试试这个", "有人试过双卡部署吗？", "可以接入外部的数据吗", "docker咋用啊，乌班图部署了三天了，还是报错[tv_大哭][tv_大哭]", "我有台老电脑 2600x 32g ddr4 亮机卡  不玩游戏 可以买4060ti 16g来学ai吗", "是单机版还是能多人使用？", "大佬，我跑了6B-32K版本的模型，但是感觉特别慢大概只有视频里的三分之一，显卡是丽台的P6000,虽然知道没有tensor core推理速度很慢，但是感觉也不至于这么慢吧，是不是6代CPU拖累了推理速度？", "请教一下，Windows部署的时候启动页面后默认用的cpu运行，怎么设置显卡运行", "多卡推理没用吧？我有三块4060 16的", "UP有群可以学习交流吗", "2080ti 22g显存[doge] 刚刚好装下百川", "我的显卡跑这个一个字一个字蹦", "4070 12g行不行", "速度很快哇[星星眼]", "UPUP，微调需要多大显存？", "up请问您运行的时候内存占用多少呀，我的16g内存好像不太够，运行cli_demo之后直接退出了", "镜像里面包含模型文件吗", "回答的精度还是不怎么行。不过应对大专的毕业论文还行", "最便宜的ai显卡，2080ti魔改22g", "速度挺快，就是傻了点[辣眼睛]", "可以用 他进行对互联网搜索 或者对本地源码进行学习吗", "和2080ti相比怎么样", "七言诗那个 你要告诉他每句七个字 他就懂了。 哈哈  挺难受", "老哥能看看你电脑配置单么", "问下使用chatglm3和直接使用官方的智谱清言网页，有啥区别，网页应该是基于glm 100b的，能力和页面交互应该都强于本地部署的吧？那为啥还需要本地部署呢？", "这个还是可以使用的，我的卡8G，使用GLM3-6b. Int8，效果还行，可以画爱心，调用工具。", "请问大佬，4060ti和4070选哪个呀", "请问你的显卡有啸叫现象吗？我昨天刚到的同款，游戏负载大了就啸叫", "4060，8G可以用吗？", "3069刚入了耕升的4060太16g，入门AI卡真香", "哈哈，我的就是4060ti 16g，生产力工具基本都能用了", "请问大神，想玩大模型的话，amd的7900xtx值得入手吗？比起4060ti 16g 如何？", "请问大神，4060ti 16g 和2080ti 22g，哪一个更好？", "苹果的m处理器，不知道效果如何", "可以本地进行自己数据的微调么", "4060感觉也不错，", "32k 显存不用16g以上？"], "2023-11-21 22:37:27"], ["video", "ChatGLM", "计算机技术", "http://www.bilibili.com/video/av875766191", "低配置部署 ChatGLM3-6B | 智谱 × 魔搭社区", "相关链接：\\n【1】https://modelscope.cn/my/modelService/deploy\\n【2】https://modelscope.cn/models/hekaisheng/chatglm3-ggml/summary\\n\\n部署文档：\\n【1】https://pan.baidu.com/s/1iv0FOShI5xB5KQZKLiupag?pwd=uhxz 提取码: uhxz\\n【2】https://pan.baidu.com/s/1aXl3to3ev9PSnSLlY66qPw?pwd=dx6i", 22656, 9, 1211, "教程, CPU, GPU, 人工智能, 阿里云, 大模型, 魔搭社区, chatglm, 智谱AI, 大模型部署", 0, ["[歪嘴]", "云部署当前部署模型task，chat不支持咋办", "已三连支持", "pip install xinference 这一步怎么具体操作", "为什么两位老师的电脑都是Mac 请问人工智能（大模型）是更推荐Mac电脑吗", "听不懂", "@ChatGLM 看私信", "哇，都到3了", "[doge]2跟3有什么区别啊，不会用", "用了zephyr 7b之后发现还是zephyr 7b更强", "25:00", "来啦来啦", "FC慎重部署哦。领了FC的免费体验包，开关了一下。FC免费的，NAS收费了。", "垂直领域精简轻部署方案", "可以有办法部署到AMD显卡上吗？用direcrml。我不会改[大哭]", "可以用window吧？", "支持ptv2微调后模型的合并，并且使用cpu的部署吗", "运行例程为啥会直接爆显存？ 之前搞了个阿里24g那个[笑哭]", "有可能转换成rknn吗？这样就可以用rk3568/3588上低成本使用了", "终于等到了[星星眼]", "已三连支持[doge]微调的时候，能输入带function call的数据集，对chat/base模型的function call能力进行微调吗", "支持[doge]", "好好好", "支持c++或者c#么，", "[支持]", "牛", "微调上线了[星星眼]", "紧紧跟进[打call][喜欢]", "视频简介:\\n相关链接：\\n【1】 链接见视频简介 \\n【2】 链接见视频简介 \\n\\n部署文档：\\n【1】 链接见视频简介  提取码: uhxz\\n【2】 链接见视频简介"], "2023-11-10 23:19:28"], ["video", "超想敲代码", "计算机技术", "http://www.bilibili.com/video/av1002416941", "部署微调ChatGlm3-6B大模型【小白0到1】", "手把手教学如何部署ChatGlm3大模型、使用LlaMa-Factory进行大模型微调。0代码部署、微调大模型，白嫖服务器，小白也能听得懂学得会！！！\\n笔记链接：http://t.csdnimg.cn/ifaH5", 21077, 24, 1035, "训练, AI, NLP, 小白教程, 大模型, chatglm, 大模型微调, 大模型部署, llama factory, loar微调", 0, ["你们有遇到这个问题吗？", "为什么我的微调以后原来的模型和微调以后的模型都回复显示一个显示\\nAttributeError: &#39;GenerationConfig&#39; object has no attribute &#39;_eos_token_tensor&#39;，一个直接不回答呢", "导出模型存储空间不够，怎么回事呢", "有别的微调数据集可以选择吗", "up主，我在调用api接口的时候，我按照您的流程，python api_server.py的时候报错了，报错内容说的是没办法导入phi3模块，但是我依赖安装是成功的，并且小黑盒我也可以使用 报错内容为RuntimeError: Failed to import transformers.trainer because of the following error (look up to see its traceback):\\n\\nNo module named &#39;transformers.models.phi3&#39; 我想问下这个怎么解决", "大佬们，为什么我安装requests的依赖时老是在中间卡住不动，该怎么解决啊\\nCollecting vllm-nccl-cu12&lt;2.19,&gt;=2.18\\n\\n  Using cached https://mirrors.aliyun.com/pypi/packages/41/07/c1be8f4ffdc257646dda26470b803487150c732aa5c9f532dd789f186a54/vllm_nccl_cu12-2.18.1.0.4.0.tar.gz (6.2 kB)在这里卡住的", "有没有大佬知道我为什么点开始训练，出现这样", "解决了吗？我也是这样[脸红]", "已拒绝连接怎么搞[大哭]", "你好博主，我在微调的时候，遇到这个情况，是不是版本不兼容。", "@超想敲代码大佬，为什么我运行之后显示File data/logical_fallacy.json not found.", "运行train-web.py时候显示没有这个文件这该去哪下载", "为什么我有点看不懂这个openapi部署是在干什么, 有没有大佬解释一下", "为什么我用GLM-4，生成文字那么慢嘞", "models下面的内容和webcodes的内容有什么区别吗？", "家人们，怎么用springboot调用阿里云微调过的模型啊", "6000组数据100轮跑3天，这时间对劲吗[灵魂出窍]", "运行大模型的时候 \\n为什么会报地址格式错误stat: path should be string, bytes, os.PathLike or integer, not NoneType", "up主，你录制的视频，最后两段很模糊，看不清，费眼睛。", "为什么下载demo的时间文件特别大，和视频里不一样[撇嘴]", "大家有遇到这个问题嘛[灵魂出窍]\\n在运行cli_demo.py小黑盒程序就报错：\\nTypeError: GenerationMixin._get_logits_warper() missing 1 required positional argument: &#39;device&#39;", "训练有没有python脚本，不是用web启动的", "up,视频三连了，但是我有一个问题，就是我从本地下载一个模型到这个云服务器上，然后他显示我这个模型不是utf-8：/mnt/workspace/LLaMA3-8B-Chinese-Chat/model-00001-of-00004.safetensors is not UTF-8 encoded   ，就用不了，这个问题怎么解决，因为我是想微调一个别人已经微调过的有中文能力的llama模型", "up,如果我自己本地下载了一个模型，想要微调这个模型，怎么把他加载到webui的名称选项里呢？", "up，您好，我每次点开始训练之后都会提示训练错误：/bin/sh: 1: llamafactory-cli: not found   说没有这个文件，这个怎么解决", "up，参照你的教程，使用你的数据集进行的训练，显卡是rtx3080笔记本，差不多5.00s/it，这个速度正常吗？\\n 63%|            | 158/250 【13:27&lt;08:06,  5.29s/it】", "chatglm3的ptuning微调有嘛[脱单doge]", "老师 我想问一下为什么我在腾讯云跑出来的network url也没用呢 跑不出来 只能跑出来本地的那个链接Local URL", "博主 可以出一期具体怎么用openai(或者其他的也可以)调用微调后的大模型api的教程吗", "那是不是通过开源的模型，再加上微调改变自我认知，就可以算作是自己的模型了？[滑稽][滑稽][滑稽]", "啊啊啊啊，TypeError: GenerationMixin._get_logits_warper() missing 1 required positional argument: &#39;device&#39;，这要怎么解决呀", "求助一下，我在启动cli_demo.py问报错\\nChatGLM：2024-07-21 17:24:35.397609: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\\nTo enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\\n2024-07-21 17:24:36.498079: W tensorflow/compiler/tf2tensorrt/bili_server/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\\nTraceback (most recent call last):\\n  File &#34;/mnt/workspace/webcodes/ChatGLM3/basic_demo/cli_demo.py&#34;, line 57, in &lt;module&gt;\\n    main()\\n  File &#34;/mnt/workspace/webcodes/ChatGLM3/basic_demo/cli_demo.py&#34;, line 43, in main\\n    for response, history, past_key_values in model.stream_chat(tokenizer, query, history=history, top_p=1,\\n  File &#34;/usr/local/lib/python3.10/site-packages/torch/bili_server/_contextlib.py&#34;, line 35, in generator_context\\n    response = gen.send(None)", "为什么运行模型时，是在用cpu呢", "为什么改了dataset_info.json文件后 一直提示找不到路径data/dataset_info.json 替换进去的时候是直接覆盖的", "为什么进入到微调界面后开始微调报这个错啊/bin/sh: 1: llamafactory-cli: not found", "为什么对话回复的时候出现好多条文件信息而且不正常回复，最后退出对话模式呢", "本机下载后，直接把安装包拖进你创建的目录如下图所示", "为什么一直git clone不下来呢 一直是没反应", "为什么打开小黑窗报错啊我是按依赖包装的呀 ImportError: cannot import name &#39;split_torch_state_dict_into_shards&#39; from &#39;huggingface_hub&#39; (/opt/conda/lib/python3.10/site-packages/huggingface_hub/__init__.py)       \\nRuntimeError: Failed to import transformers.generation.bili_server because of the following error (look up to see its traceback):\\ncannot import name &#39;split_torch_state_dict_into_shards&#39; from &#39;huggingface_hub&#39; (/opt/conda/lib/python3.10/site-packages/huggingface_hub/__init__.py)", "执行cli_demo.py报错：\\nUnicodeDecodeError: &#39;ascii&#39; codec can&#39;t decode byte 0xe6 in position 0: ordinal not in range(128)", "已解决：\\n/bin/sh: 1: llamafactory-cli: not found\\n\\n解决办法：安装依赖\\npip install -e &#34;.【torch,metrics】&#34;", "解决报错：\\n网址为 http://0.0.0.0:7860/ 的网页可能暂时无法连接，或者它已永久性地移动到了新网址。\\nERR_ADDRESS_INVALID\\n第一天运行能正常跑出炼丹炉，第二天一模一样的操作，但是报错了。csdn等经验贴让改成localhost，不好使。后来捋了一下逻辑，我们是访问的云端，究其根本还是要知道阿里云的ip地址才行。\\n解决办法：\\nlaunch()后，将网址改成https://408117-proxy-7860.dsw-gateway-cn-shanghai.data.aliyun.com/，当然，要看你自己所在的区域在阿里云给你分配的区块，我在安徽给我分配的是上海的资源，有的是杭州等地，就要将shanghai改成hangzhou，看自己的区块，在首页的左上角有，亲测有效，希望能帮到各位", "请问为什么我下载依赖下了几个小时还没结束？而且拉的东西居多巨大，跟up不一样？", "webui选好数据集后点击开始terminal输出&#39;llamafactory-cli&#39; 不是内部或外部命令，也不是可运行的程序\\n或批处理文件。怎么解决啊求助", "我在云服务器上部署chatglm大模型时候运行python cli_demo.py后，提问会出现“UnicodeDecodeError: &#39;ascii&#39; codec can&#39;t decode byte 0xe6 in position 0: ordinal not in range(128)”错误，有没有相同情况[保佑]", "up,请问这样怎么办?", "最后一步输入pip uninstall flash-attn -y 之后显示未安装flash-attn  这是为啥呢  希望大佬们解答下", "博主，我想问一下，训练完之后在网页提问不回答。导出到本地之后运行报错，setattr(self, key, value)\\nAttributeError: property &#39;eos_token&#39; of &#39;ChatGLMTokenizer&#39; object has no setter", "微调的时候显示依赖冲突怎么解决", "有笔记吗", "您好可以把资料分享一下吗", "跑完后报错：KeyError: &#39;base_model.model.transformer.encoder.layers.0.input_layernorm.weight&#39;", "各位大佬，出现这个错误怎么解决呢RuntimeError: Failed to import transformers.trainer because of the following error (look up to see its traceback):\\n/opt/conda/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE", "照up的顺序，使用阿里云服务器，可是运行cli_demo后，跟程序聊天时，发一个消息就会就会这样ChatGLM：2024-06-21 20:00:13.234424: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\\nTo enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\\n2024-06-21 20:00:14.189692: W tensorflow/compiler/tf2tensorrt/bili_server/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\\nTraceback (most recent call last):\\n...........................................\\nUnicodeDecodeError: &#39;ascii&#39; codec can&#39;t decode byte 0xe6 in position 0: ordinal not in range(128)，部分截图，来个好心的大佬救救我[大哭][大哭][大哭][大哭][大哭]", "up主那个部署笔记可以发一份吗，一键三连了[星星眼]", "up讲的不错", "请教大家一个问题，我跟着视频最后一步训练出来了微调的模型，改好路径之后打开小黑窗测试，结果怎么还是原来的模型（问：你是谁？答：我是清华大学巴拉巴拉。。）求教哭了[大哭][大哭][大哭]", "进了炼丹炉到最后一步   选好数据集之后点击开始  说未检测到CUDA环境  这是为啥呢 大佬们[笑哭][大哭][大哭]", "首先给up点赞投币了，然后我在用pip install -r requirements.txt 安装依赖的时候，你那就下了一点东西，我这怎么一堆东西[笑哭]好多七八百兆的东西要下啊", "BV1Cx4y1m7Gd", "请问为什么会调用这个data.json文件呀，data里面也没有data.json，也不是我定义的数据集，请问是哪块要调用它呀？", "笔记", "为什么我安装库和依赖没完没了啊，一直在下载，而且文件很大", "求笔记代码", "在运行python cli_demo.py 是报错了\\nTraceback (most recent call last):\\n  File &#34;/public/home/wangyu_zwm_2606/webcodes/ChatGLM3/basic_demo/cli_demo.py&#34;, line 8, in &lt;module&gt;\\n    tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH, trust_remote_code=True)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File &#34;/public/home/wangyu_zwm_2606/anaconda3/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py&#34;, line 847, in from_pretrained\\n    return tokenizer_class.from_pretrained(\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File &#34;/public/home/wangyu_zwm_2606/anaconda3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py&#34;, line 2089, in from_pretrained\\n    return cls._from_pretrained(\\n           ^^^^^^^^^^^^^^^^^^^^^\\nRuntimeError: Internal: could not parse ModelProto from /public/home/wangyu_zwm_2606/models/chatglm3-6b/tokenizer.model", "点击训练的时候报这个错，\\n友大佬知道吗", "可以，也是成功的可以微调了", "博主我在启动api_server.py报错了，\\n\\nRuntimeError: Failed to import transformers.trainer because of the following error (look up to see its traceback):\\n/opt/conda/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE", "CUDA_VISIBLE_DEVICES=0 USE_MODELSCOPE_HUB=1 python src/train_web.py 执行完这步后有个错误 是  ValueError: Custom values are not supported when `multiselect` is True.\\nIMPORTANT: You are using gradio version 3.38.0, however version 4.29.0 is available, please upgrade.   想问下大佬们这是为啥呢", "阿里云这个能白嫖多久大概，怕扣费了，另外这个教程改用glm3-32k的模型也是一样的吗？", "博主求笔记", "UP主您好，我想在阿里云上租一个服务器，有啥参数推荐吗", "@超想敲代码 博主请问这种是什么问题", "我的阿里云服务器网速怎么那么慢呀哈哈", "为什么我安装依赖的时候就卡在了第六行呢？[大哭]", "求问跑起来llama面板显示没有找到api可能是什么原因啊 前面api运行起来了没问题", "大佬们 这个错是为啥啊", "微调导出的sft模型怎样变成api调用呢", "请问现在训练数据集的格式需要更改吗", "Setting eos_token is not supported, use the default one.请问这是什么问题呀？", "解决大家在阿里云中使用更新后的llama-factory的几个问题，希望有帮助：\\n1.新版本是运行webui.py进入网页\\n2.运行webui.py时，报错TF-TRT Warning: Could not find TensorRT，可以直接忽略，不影响\\n3.运行webui.py时，报错：ImportError： cannot import name &#39;MultiModalData&#39; from &#39;vllm.sequence&#39; （/usr/local/lib/python3.10/dist-packages/vllm/sequence.py）\\n就把vllm卸载掉：pip uninstall vllm，因为vllm至少要使用0.4.0版本以上的，所以重新安装：pip install vllm == 0.4.0\\n4.进入页面后全显示error，是因为服务器中网络端口的问题\\n 在安装llama（git clone https://github.com/hiyouga/LLaMA-Factory.git）的时候，除了UP主笔记中的那些命令，还需要：\\ncd LLaMA-Factory\\npip install -e .【torch,metrics】\\npip install --no-deps -e .\\n\\n最后，运行 export GRADIO_SERVER_PORT=7860 GRADIO_ROOT_PATH=/${JUPYTER_NAME}/proxy/7860/\\n最后运行CUDA_VISIBLE_DEVICES=0 USE_MODELSCOPE_HUB=1 python src/webui.py\\n就可以顺利进入“炼丹炉”微调页面了\\n(如果你使用autodl，那就运行pip install gradio==4.10.0 即可）", "web版的不支持多卡微调，多卡的得用命令执行", "微调开始的CCUDA那一步报错了，发现web.py没有了，上个星期更新了文件，怎么解决哇", "笔记", "Up解决gradio webui会错误链接的问题了吗", "up声音很苏啊，已经关注加三连，求笔记📝", "请问运行api的时候老是报错\\nroot@dsw-372446-84599bb885-gxn2l:/mnt/workspace/ChatGLM3/openai_api_demo# python api_server.py\\nTraceback (most recent call last):\\n  File &#34;/mnt/workspace/ChatGLM3/openai_api_demo/api_server.py&#34;, line 47, in &lt;module&gt;\\n    from tools.schema import tool_class, tool_def, tool_param_start_with, tool_define_param_name\\nModuleNotFoundError: No module named &#39;tools.schema&#39;\\n这个包还安装不上怎么办", "已三连求笔记", "想问一下我为啥没有train_web文件", "到达安装LLaMA-Factory阶段，最后提示python: can&#39;t open file &#39;/mnt/workspace/LLaMA-Factory/src/train_web.py&#39;: 【Errno 2】 No such file or directory。是怎么回事呀？", "博主能教一教怎么用chatglm进行文本分析吗～如果博主会的话，谢谢谢谢！", "大佬请问一下，为什么有点云服务器可以打开那个local url，有点不行。我用的是矩池云，打不开那个前端链接。", "求笔记", "python: can&#39;t open file &#39;/mnt/workspace/LLaMA-Factory/src/train_web.py&#39;: 【Errno 2】 No such file or directory按照步骤来了，为什么没找到路径", "请问游戏显卡12G可以吗", "up,你好，发不了问题的图片，就是每个框框都像计时器一样然后12.5s,12.6s这样一直变，但就是加载不出来昨天chatglm可以,今天百川7b就不可以了）以下是我做过的努力：把gradio更新到4.0.0；使用python虚拟环境而不是conda创建；git checkout v0.6.0但未成功；unset http_proxy https_proxy all_proxy # 关闭代理\\npython -m llmtuner.webui.interface用这段代码是上个评论的情况CUDA_VISIBLE_DEVICES=0 python src/train_web.py用这个是空白界面", "求问，我在输入python cli_demo.py后出现这种情况了[tv_难过][tv_难过][tv_难过]Traceback (most recent call last):\\n  File &#34;/mnt/workspace/webcodes/ChatGLM3/basic_demo/cli_demo.py&#34;, line 8, in &lt;module&gt;\\n    tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH, trust_remote_code=True)\\n  File &#34;/opt/conda/envs/llm/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py&#34;, line 847, in from_pretrained\\n    return tokenizer_class.from_pretrained(\\n  File &#34;/opt/conda/envs/llm/lib/python3.10/site-packages/transformers/tokenization_utils_base.py&#34;, line 2089, in from_pretrained\\n    return cls._from_pretrained(\\n  File &#34;/opt/conda/envs/llm/lib/python3.10/site-packages/transformers/tokenization_utils_base.py&#34;, line 2311, in _from_pretrained\\n    tokenizer = cls(*init_inputs, **init_kwargs)\\n    return self.sp_tokenizer.num_tokens\\nAttributeError: &#39;ChatGLMTokenizer&#39; object has no attribute &#39;sp_tokenizer&#39;. Did you mean: &#39;_tokenize&#39;?", "llama运行web那里报错的可以去看看github llama官网教程，应该是更新了库代码，我今天复制blog里的代码是报错的[脱单doge]", "博主能给个笔记吗[脱单doge]", "root@dsw-367504-598b5f54bf-5wz45:/mnt/workspace/LLaMA-Factory# CUDA_VISIBLE_DEVICES=0 USE_MODELSCOPE_HUB=1 python src/train_web.py\\n\\nFactory/src/llmtuner/chat/chat_model.py&#34;, line 7, in &lt;module&gt;\\n    from .vllm_engine import VllmEngine\\n  File &#34;/mnt/workspace/LLaMA-Factory/src/llmtuner/chat/vllm_engine.py&#34;, line 14, in &lt;module&gt;\\n    from vllm.sequence import MultiModalData\\nImportError: cannot import name &#39;MultiModalData&#39; from &#39;vllm.sequence&#39; (/opt/conda/lib/python3.10/site-packages/vllm/sequence.py)\\n这是什么错误啊？有相同问题的吗", "你好up主，这个要这么解决呀，我第一次部署可以进入llamafactory，第二次就会出现这个错误[大哭][大哭][大哭]cannot import name &#39;MultiModalData&#39; from &#39;vllm.sequence&#39; (/opt/conda/lib/python3.10/site-packages/vllm/sequence.py)", "upup 我在运行llama 网页那个命令的时候，出现这个报错。我是先把gradio降到了4.0（是之前报错的）这个报错我不知道该怎么解决了，up可以帮助我一下吗", "求笔记up", "为啥自定义数据集一直放不进去呀[笑哭][笑哭][笑哭]", "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\\n为什么我启动后 显示这个啊。 不知道为啥照着up一步一步的来 却没有在GPU上运行。", "博主的笔记能发一下吗[脱单doge]", "好的，谢谢", "为什么我永远显示gpu内存不足，为什么up右上角能实时监控显存使用率啊，在哪能调出那个", "显示“嗯… 无法访问此页面网址为http://0.0.0.0:7860/ 的页面可能存在问题，或者已永久移动到新的网址。\\nERR_ADDRESS_INVALID”该怎么办", "嗯… 无法访问此页面网址为http://0.0.0.0:7860/ 的页面可能存在问题，或者已永久移动到新的网址。\\nERR_ADDRESS_INVALID", "为什么打开后，开始训练，就报\\nError\\nConnection errored out.", "up的笔记软件叫啥？", "up你好，如果是多轮微调，最终怎么合并到原来的大模型啊？", "这个接口能通过公网调用吗", "在pip uninstall flash＿attn －y的时候，他就警告，说Skipping flash-attn as it is not installed.这个对后面微调有影响吗", "我跑起来会报这样的错，怎么解决了？", "爱你宝贝～", "怎么把数据库中的数据转成训练数据集啊？", "这种怎么办", "阿里云huggingface的模型没法下载，up也这样吗", "这是怎么了？", "好教程确实是手把手，三连了", "微调训练之后怎么去设置api呀，想给别人用的话应该怎么搞呀请问有人知道吗[大哭]", "点击预览命令是错误诶，看不了", "up请问这个问题怎么解决呢", "up,你好，我想问下就是我按照教程弄好了，但是问问题的 时候只要超过4个子就直接报错怎么解决啊UnicodeDecodeError: &#39;utf-8&#39; codec can&#39;t decode bytes in position 9-10: invalid continuation byte", "为什么说未检测到CUDA环境啊，怎么解决[大哭]", "按照up的顺序，使用阿里云服务器，可是运行cli_demo后，跟程序聊天时，发一个消息就会报错RuntimeError: &#34;addmm_impl_cpu_&#34; not implemented for &#39;Half&#39;。 查了一下是因为用的cpu的原因。小黑窗为什么是cpu在跑阿[委屈]，也切换不过来", "运行到一半就报错，到底是为什么[大哭][大哭][大哭]", "想问一下启动的时候这样咋办呀", "我想问一下，如果使用命令，可以查看当前训练任务的状态和进度条吗？如果不用llama-factory本身提供的训练界面，将llama-factory作为镜像，自己开发页面，但是直接调用llama-factory提供的接口，也是可以训练的，但是怎么查看当前训练任务的状态呢？没找到对应的监控的接口，问一下up主研究过这些吗？", "我的小黑窗为什么是cpu在跑，速度好慢", "问一下，说未检测到cuda环境[笑哭][笑哭]可是我装了cuda呀", "RuntimeError: &#34;addmm_impl_cpu_&#34; not implemented for &#39;Half&#39;小黑窗输入问题显示这个怎么解决呢", "挺好的，有没有群，大家互相交流", "我想问一下,我按照步骤来的,每次到三十多次,就会出现error,然后llama就不打印日志了,但是终端显示还是在继续训练,也打印着信息,终端也没有显示异常啥的,最多只有一个警告,也不是异常,该如何解决呢", "self_cognition中都是&lt;MODEL&gt;和 &lt;NAME&gt;，在什么地方自定义修改这两个值，还是在这个文件中全部替换？", "想问下，数据集JSON中的占位符是怎么设置的", "数据集刷新不出来，重启也不行[笑哭]", "为什么运行完了，数据集那一栏是灰色的点不开呀", "file_sha1那一串码是什么意思啊，up", "LLaMA-Factory启动后点击http://0.0.0.0:7860弹出的页面访问不了，Connection Errored out，请问怎么解决", "讲的太好了up！请问后续能出一期RLHF微调ChatGLM3-6b得教程吗？", "看了博主的视频，讲解的很详细，很棒。\\n博主在模型微调的时候，有两次显示GPU使用太高导致进行不下去，博主不得不重启服务器。其实不用重启服务器，那是因为起的终端比较多。如下图所示，Shut Down 不需要的终端，显存就会释放。如果不确定是那个终端占用显存比较高，就Shut Down All。", "up我点进gradio的链接就是这样的，搜了一下，发现没有相关资料解决这个问题，up能帮助一下吗", "请问微调的时候数据集加system角色了吗", "为啥我的llama board打开总是这样的，人麻了[大哭]", "阿里云那里怎么操作的？", "微调了几次，每次50轮，还是没改变大模型的自我认知[笑哭]不知道是不是自己训练的数据集有问题", "显存占用异常可以打一下nvidia-smi看下占用进程，如果没用直接对着pid号 kill  -9就行", "做的太好了，博主，我想问一下第一训练过后，我想第二次训练的时候不去训练第一次的数据，就是可以接着去训练这种。下期视频可以出一下嘛。已点赞三连。我把我全班同学叫来点赞[吃瓜]", "阿里云网页版部署打不开，除了换服务器外有别的解决方法嘛？", "导出模型报错：    raise ValueError(f&#34;{tensor_name} is on the meta device, we need a `value` to put in on {device}.&#34;)\\nValueError: weight is on the meta device, we need a `value` to put in on cpu.", "插眼", "[奋斗][奋斗][奋斗][奋斗][奋斗][奋斗]", "[龙年][龙年][龙年]", "笔记：https://blog.csdn.net/weixin_44480960/article/details/137092717?spm=1001.2014.3001.5501"], "2024-03-28 01:01:49"], ["video", "AI日日新", "计算机技术", "http://www.bilibili.com/video/av875171515", "ChatGLM3-6B 对比 Qwen-14B，到底谁更强？", "", 15220, 2, 172, "清华大学, 阿里, 大模型, 必剪创作, AIGC, 魔搭社区, Qwen-14B, Qwen-14B-int4, 1024·2023活动征稿, 1024打卡挑战, ChatGLM3-6B", 0, ["其实讲道理。。还是用gpt3.5划算。。3.5真的不贵用得起。。4是贵得离谱。。", "24g显存跑哪个模型好", "这个模型支持的token数是多少", "14b可以改成int8量化吗？需要多大的显存呢？", "请问UP，为什么我建好知识库准备往里面导入学习文档的时候总是提示“未找到知识库”，也无法删除知识库", "请教UP一个问题，想微调的话，是基于Qwen-14B还是Qwen-14B-chat更好？谢谢。", "chatGLM3-6b在int4精度下显存占用5-6G是真实的吗", "个人使用体验，我是用的chagglm3－6b－32k和Qwen－14b－chat，让他们两个在相同prompt下角色扮演，感觉glm3更富有人情一点[藏狐]", "6B的参数和14B的参数不在一个起跑线上吧。", "如果你录入规则之类的判断语句，千问都比不过chatglm3,更别说chatgpt3.5", "光比个分离可不行，glm3的function calling和code interpreter也得比一下", "3-6B太容易卡无限输出bug了，我这边要调疯了", "https://b23.tv/mall-1w1xV-xnVzl2NRLs", "请问一下有没有能直接用的启动器介绍一下啊？", "你不能光凭一个问题来比较", "想问一下int4对模型精度影响大吗", "qwen是阿里那个吗？", "拿14打6  [笑哭]", "我们公司生产在用 gpt3.5。最近在测试 qwen14b。根据文本输出 json。说实话 qwen效果已经和 gpt3.5 差不多了。唯一区别就是qwen 的提示词一定要写的简单明确。[喜极而泣]。gpt3.5 就可以随意一些。", "https://b23.tv/mall-1w1xV-ydvOeCOthw", "和百川2比呢？", "8g显存没得选[笑哭]", "up up 可以测试一下他们的工具调用能力吗 founction calling"], "2023-10-28 21:21:51"], ["video", "frontEndBugMaker", "计算机技术", "http://www.bilibili.com/video/av1051768122", "【保姆级教程】使用ChatGLM3-6B＋oneAPI＋Fastgpt＋LLaMA-Factory实现本地大模型微调＋知识库＋接口管理", "使用了清华开源的大模型chatGLM3-6b进行本地部署，LLaMA-Factory进行大模型微调，使用fastgpt的知识库连接本地大模型，使用oneAPI进行接口管理。", 14315, 8, 1157, "教程, 模型, 微调, 编程开发, 保姆级教程, 知识库, 本地搭建大模型", 0, ["请问本地部署oneapi的base url怎么填", "为什么在运行’web_demo_streamlit‘时生成的链接无法访问。我具体应该怎么做呢，诚心发问", "大神！我按照视频到One Api 测试渠道那里，报错是怎么回事", "我想问一下我遇到的问题就是我在阿里云部署完了用高级编排的调用工具模块的会出现LLM api response empty但是我本地大模型GLM4（glm4-9b-chat）没有问题就Fastgpt高级编排的调试会出错是什么原因", "大佬你好，我用浪潮人工智能平台进行操作的，在运行web_demo_streamlit.py的时候打不开网址，这个平台也没找到安全组设置，请问这种情况该怎么办？", "我也一样啊", "大佬你好 我想问一下就是docker -compose pull一直显示连接超时一下下载不了要怎么解决呢", "为什么fastgpt分享给别人的链接，别人无法打开", "请问接口是api接口吗", "各位请问这种问题如何解决", "up你好，我想请教一下在安装依赖的时候这个错误是什么原因怎么解决啊", "请问这个云服务器该怎么选呢", "求助 到最后llamafactory运行的时候没有train_web.py，我看git上也是没有 应该运行哪个啊[大哭]", "大佬这个通过写API调用吗", "您好，我在python api_server.py时候，会报safetensors_rust.SafetensorError: Error while deserializing header: HeaderTooLarge，这样的错误，请问您知道怎么解决嘛", "腾讯云streamlit生成的链接无法访问，安全组也已经全部放开了，还是不行", "三连了", "大佬们，我在wls2上部署的oneapi，想请教一下那个打开它的IP应该怎搞啊？[大哭]", "请问大佬，我无法通过弹性 ip 来打开 oneapi，但是终端显示我已经是运行了 oneapi 的", "有没有炒股用的AI", "这样部署可以成功，但是没有并发能力，chatglm3官方提供的api_server.py,接口不支持并发，请问楼主处理过这个问题嘛", "腾讯云glm3拉不下来怎么搞", "部署在自己的电脑上，可以对接到微信小程序吗", "￥1.26一个小时，贵不贵，这个时间是怎么算的，不知道一个月一年多少钱", "问问题不回复怎么办", "可以用CPU跑不", "解决了吗", "腾讯云的glm3拉不下来，华为云的hecs l实例无法启动docker怎么办呀，需要购买旧版的吗", "大佬讲的好啊，期待下一个教学视频分享", "up你好，我在win10系统下微调的，在LLaMA-Factory页面点击开始的时候他显示未检测到cuda环境，怎么解决啊，我cuda有安装啊12.2版本的", "\u200d我自己部署了个fastgpt，然后用的glm3的模型，这个模型是五河川那边直接下的一个bat启动的整合包，我想自己做微调，应该怎么弄， 看了视频有点不明白，llama-factory弄不来，能不能帮帮忙，已一键三连", "大佬，已三连[打call]\\n我目前在阿里云平台上已经按您的步骤搭建好了，也是跟楼上兄弟一样的思路，先拿gpt帮我把学校文件转成数据集格式，然后安上。\\n想请教您一下，假如说想知道训练的效果，除了直接问问题还能怎么看？如果能量化就更好了，看论文中有比较Precision Recall F1等等的，想知道要如何获取这些呢？\\n另外损失率曲线可以导出吗？", "大佬为什么为一直启动不了one-api呢？无论重新部署多少次，都是一直在重启。", "用腾讯云第一步下glm3模型就卡主了，半个多小时了没反应，用autodl就很快，腾讯这里是要开加速么", "端口号在哪更改啊！", "大神，oneapi两个渠道，一个渠道测试通过，一个测试不通过，两个渠道的url只有端口不一样，这怎么回事", "救命啊！\\nInvalid URL怎么办！！！！！！！！！", "插眼[星星眼][星星眼][星星眼][星星眼][星星眼]", "大哥，报这个错误应该怎么解决，主要是哪里的问题。", "大佬，登陆fastgpt显示network error是什么原因啊", "Up主，我这边pull不了fastgpt怎么弄？", "太牛了兄弟", "怎么开放出来api给别的项目调用", "我在win11下，通过docker把整套搭建出来了", "我们也想建立一个类似的，请看看你的私信，然后联系我。", "UP你好，我想请教一下，m3e向量库可以用pinecone替换吗", "大佬们，docker无法启动，这个咋解决[大哭]", "up你好，我配置到最后一步报错了，不知道为啥如图，oneapi里面测试也通过了，望解答，万分感谢", "请问这段代码在哪里执行？@", "你好我想问一下，fastgpt出现弹窗“接口报错或返回为空”是什么原因造成的？", "有小伙伴知道，这个是什么原因照成的以及如何解决嘛？", "和刚刚一样的情况这是为什么呢", "你好，我没有在服务器上部署，我全部在电脑上安装的，现在要在oneapi中，添加渠道，那我得Baseurl该如何填写呢？", "请问一下，这是为什么呐", "UP主你好，感谢你分享的教程，很有帮助。有个问题和您请教下，就是如果我让GLM3输出“佺”这个字体，它却错误识别为“全场”或者是“伽”，请问这是什么原因？以及可能的解决办法是啥？", "docker-compose下的慢的话，可以本地下载再上传，改个名字就行", "安装docker compose时遇到System has not been booted with systemd as init system (PID 1). Can&#39;t operate.\\nFailed to connect to bus: 主机关闭 要怎么解决呀[大哭]", "up你好，我有很多校规pdf文件，想要转化成结构化的问答数据集用于微调训练，请问可以如何转化？", "web_demo_streamlit‘时生成的链接无法访问。能请教下具体怎么解决么？", "请问fastgpt为什么会connection error", "这是为什么\\n[辣眼睛]", "UP主加油！看好你噢~", "t请问腾讯源无法安装curl，换源也不行，是咋回事呀？", "大佬为什么我配置文件没有改动，fastgpt 用root登录报用户未注册呀？求助", "up主我想问下，如果有多次训练模型的需求，需要每次都要导出然后把模型路径替换掉吗？ 那每次都是训练全量的数据？", "已三连。请问up，整个应用搭建好，如果想要部署到自己私有的内部系统里，还需要些什么步骤喃？是不是还需要整个打包创建一个api供调用？", "我的天 up 还玩梦三国呢，我小时候也玩梦三[doge]", "为什么不早点出呢！！！！折腾了很久了。感谢up主！", "up主你好，想请教一下为什么在运行’web_demo_streamlit‘时生成的链接无法访问。", "大神，可以发下资料吗", "投币，稍后再看", "大佬真乃及时雨，我现在也在鼓捣ChatGLM+langchain-chatchat自建知识库问答不准确的问题", "讲的太厉害啦[星星眼][星星眼][星星眼][星星眼][星星眼] 棒棒棒"], "2024-03-17 18:45:12"], ["video", "木羽Cheney", "职业职场", "http://www.bilibili.com/video/av708746434", "30分钟学会运行ChatGLM3-6B模型的P-Turning V2高效微调及全量微调代码", "工作中急需微调Chat GLM3-6B模型，却不懂微调原理怎么办？这个视频中，即使大家对大模型微调的原理还不太了解，也能快速开始实际操作。我会帮助大家通俗的理解目前主流的高效微调方法并着重介绍如何快速运行ChatGLM3官方支持的P-Turning v2微调技术。此外，为了帮助大家更好地理解和实践这些技术，我还为大家准备了视频配套超详细的（34页）PDF文档，无套路，领取方式见置顶评论~", 8605, 85, 641, "高效, 微调, 大语言模型 (LLM), ChatGLM3", 0, ["666", "可惜没有代码实现", "666", "666", "666", "666", "666[星星眼]", "666", "666", "666", "666[星星眼][星星眼][星星眼]", "666", "666", "666", "666三连，求资料", "666", "666[脱单doge]", "666", "666", "666，已三连，求大佬发资料[doge][妙啊][微笑]", "666", "666", "666", "666", "666", "666", "666", "666", "chatglm3-6B没有验证文件么？", "666", "666", "666", "666", "666[微笑]", "666", "666", "666", "666", "666[脱单doge]", "666", "666", "666", "666", "666", "666", "666", "666", "666", "666", "666", "666", "666", "666", "666", "666", "666", "666", "666[喜欢]", "666", "666[给心心]求发已三连！", "666", "666", "666", "群里那个人不会是你吧", "666", "666", "666[脱单doge][脱单doge][脱单doge]", "666", "666", "666", "你好，请问我微调的多轮官方数据集，微调过程loss一直为0", "666", "666[doge]", "UP主加油！看好你噢~", "666", "666", "666", "666", "666", "666", "666", "666", "666", "666", "666", "max_source_ len是输入的提问最大数？", "666", "666", "666已三连，求分享", "666", "666", "666", "666", "666", "666", "666", "666", "666", "666", "微调完毕后，怎么评估微调的效果怎么样，怎么证明调后性能更好，好了多少？", "666 三连了", "666", "666", "666", "感觉还是你这个说的比较明白些", "666", "666", "666", "666", "666", "666", "666", "666", "666", "666", "666", "666", "666", "666", "666", "666", "666", "666[doge][doge][doge]", "666", "666", "666", "666", "666", "怎么把自己的数据转化成微调数据呢，有相关的库或吗？", "666", "[打call][打call][打call]", "666"], "2024-01-13 20:00:00"], ["video", "AI日日新", "计算机技术", "http://www.bilibili.com/video/av277665499", "ChatGLM3-6B，启动！", "", 6418, 1, 83, "清华大学, 文本生成, 必剪创作, 智谱, AIGC, chatglm, 中文大模型, 1024·2023活动征稿, 1024打卡挑战, chatglm3, chatglm3-6b", 0, ["qianwen 比gpt-4还分高？", "可以进入demo,但是一对话就出现这个错误：RuntimeError: &#34;addmm_impl_cpu_&#34; not implemented for &#39;Half&#39;", "什么lj榜单都往外放是吧？", "看好chahglm3-3b，这个强啊", "什么辣鸡排行榜？6b打gpt4，1.3b打chatgpt和Claude亏他想的出来", "pretraining on the test set is all you need[doge]", "感觉baichuan2效果也不错呢，它和qwen比怎么样呢", "https://b23.tv/mall-1w1xV-ydvOeCOthw", "不知道跟qwen比咋样"], "2023-10-27 23:36:38"], ["video", "编程分享录", "计算机技术", "http://www.bilibili.com/video/av1753100101", "【大模型微调】ChatGLM3-6b大模型微调 | 基于开源的大模型的微调 | 使用自己的数据集来微调大模型 | 垂直领域大模型 | lora微调大模型", "【大模型微调】ChatGLM3-6b大模型微调 | 基于开源的大模型的微调 | 使用自己的数据集来微调大模型 | 垂直领域大模型 | lora微调大模型\\n本视频中使用的是开源的大模型ChatGLM3，微调脚本为官方提供\\n数据集可以自己制作，然后微调成垂直领域的大模型\\n更多内容欢迎关注我", 5032, 1, 375, "微调, 大模型, lora, LLM, ChatGPT, 大语言模型 (LLM), lora微调大模型, 本地专有大模型", 0, ["up可以私下分享下你视频中自己制作的数据集吗，已经关注你了", "请问一下 这是你讲的吗？", "train过程成功了 eval过程失败了", "大佬，遇到过这个问题嘛", "为啥p-tuning的微调方式没有了。。", "表格类数据集该怎么制作啊", "up你好，网站崩了", "合并的代码", "UP ，请教下自己制作的数据集迭代到500步开始报错，有啥原因嘛？", "怎么样可以通过面试啊,好焦虑啊", "chatglm-6b在进行Lora微调时调整了几个transformer，lora微调是调整大模型里的人所有transformer吗？UP主有空交流下", "模型合并代码共享一下，为什么下载的模型没有合并模型代码呀", "微调数据集默认是有多轮对话能力的吗", "可以私信下文档麻？", "合并模型原理是啥", "up你好，如果是多次微调，怎么和原来的模型合并啊？", "可以发一下文档嘛，感谢up", "up你好，请教一个问题。\\n在台式工作站上lora微调chatglm3-6b，跑到一半时，显卡温度56℃，GPU占用99%，训练正常进行，但是显示屏突然黑了，只能看到鼠标，物理重启后恢复正常。\\n设备信息：13代i9，32G+1T固态，4090 24G。\\n平时没训练模型时，大概每半小时屏幕会突然闪一下，就是瞬间变黑又恢复，一闪而过。\\n求指导，非常感谢！", "UP主 可以分享一下 数据集吗？", "问一下up，这个装在电脑里的模型和手机上的软件有什么不同吗？", "up主是初中生？", "up  我到training的时候报了RuntimeError: &#34;addmm_impl_cpu_&#34; not implemented for &#39;Half&#39;，有什么解决办法吗", "首页来的"], "2024-04-13 11:43:14"], ["video", "我学还不行阿", "计算机技术", "http://www.bilibili.com/video/av620460202", "【开源】ChatGLM3-6B发布了！大升级！轻松接入现有项目接口，支持实时上传文档-Chatglm3-6B、大语言模型、模型微调、模型部署、人工智能、大模型", "来源于网络，侵删\\n关注公众号：AI技术星球，回复暗号：985\\n即可获取配套课程资料+60G人工智能精选资料包！打kaggle比赛/论文带读/论文指导/CV/NLP知识恶补/技术答疑/提升等均可咨询\\n【1.基础知识】：Python基础+高数基础\\n【2.机器学习理论入门】：机器学习经典算法详解\\n【3.机器学习实战项目】：Kaggle竞赛案例/推荐系统实战/数据分析建模等\\n【4.深度学习理论入门】：必备框架（Pytorch+TensorFlow）+神经网络模型基础\\n【5.计算机视觉实战项目】：图像处理+YOLO", 4229, 20, 119, "教程, 微调, 计算机技术, 大模型, agent, 迁移学习, 模型训练, 大语言模型, chatglm, chatglm3-6B", 0, ["如何微调呀up主", "Setting eos_token is not supported, use the default one.\\nSetting pad_token is not supported, use the default one.\\nSetting unk_token is not supported, use the default one.最后一步这三个报错是怎么一回事啊up", "很不错的项目，刚刚在我的本地部署完。不知道可以如何微调系a~"], "2023-11-04 16:44:57"], ["video", "会算法的猫", "日常", "http://www.bilibili.com/video/av365368404", "大模型chatglm3-6b之开外挂", "大模型agent", 4155, 0, 184, "NLP, 大模型, Agent, chatglm3", 0, ["开源吗", "4070可以本地部署玩玩嘛", "一眼大佬", "一、车主LN最新的大模型，其中包括了工具调用的特色功能。通过四个步骤，大模型可以理解用户的问题并调用相应的接口得到答案。\\n00:02 - 车主LN发布了三杠6V大模型，开发了工具调用特色功能\\n01:30 - 告诉大模型有哪些接口，作用是什么，让模型判断调用哪个接口\\n02:32 - 把整个接口列表放到字典中，传入对话过程中去\\n二、如何使用Python实现语音助手，包括输入温度和风力来推荐穿着，以及查询当地天气等功能。同时还介绍了大模型的使用和函数的定义。\\n03:01 - 输入温度和风力可以得到穿着建议\\n03:36 - 使用工具类来回答问题\\n05:25 - 将响应和历史记录传入run test方法进行判断和执行\\n三、如何使用模型来推荐衣服，通过调用外部接口获取北京的天气信息，并将结果传递给大模型进行处理，最终得到推荐结果。\\n06:00 - 通过调用外部接口获取北京天气，并传入大模型进行推荐\\n06:26 - 模型调用第二个接口，根据风力和温度等参数推荐创意\\n08:40 - 模型可以调用外部接口，使回答更加精准\\n--本内容由AI视频小助理生成，关注解锁AI助理，由@Dustsdk 召唤发送", "@AI视频小助理", "好厉害啊，可以出6b的微调教程吗up", "【内容总结】 这是一个关于大模型chatglm3-6b以及开外挂的视频。视频介绍了LN发布的最新大模型的新功能，即工具调用。讲解了具体的使用步骤和实现原理。演示了如何定义接口以及如何根据用户问题和中间步骤来调用接口得到最终答案。演示过程中展示了两个简单的接口的定义和调用过程。通过传入参数和模型的运行，得到最终的结果。\\n\\n【时间线】\\n- 00:02 - LN发布了最新的大模型chatglm3-6b，介绍了新的功能。\\n- 00:14 - 介绍了工具调用的特色功能。\\n- 01:24 - 详细讲解了接口的定义，包括方法名称、输入参数和输出字段。\\n- 03:18 - 演示了如何根据用户问题和中间步骤来调用接口得到最终答案。\\n- 07:57 - 展示了模型调用外部接口后得到更有针对性的回答，使回答更加精准。\\n\\n【可能感兴趣的问题】 (触发提问请回复: 问一下+问题)\\n1. LN的大模型chatglm3-6b有哪些新功能？\\n2. 如何定义和调用接口来实现工具调用？\\n3. 大模型是如何根据用户问题和中间步骤来最终回答问题的？\\n\\n内容由AI自动总结, 总结内容仅供参考~ @Maynor996 触发了视频总结, 触发方式是 @有趣的程序员 总结一下", "@有趣的程序员 总结一下", "会算法的女孩很少见啊", "[doge]这代码怎么这么眼熟，哦原来是我写的啊，那没事了[脱单doge]，竟然有妹子搞这个，相互学习啊[呲牙]", "卧槽，竟然有妹子搞这个头秃东西", "围观，今天刚用p102 跑int4量化跑通", "[吃瓜]还是看妹子的视频看得懂~", "[doge]是妹子吗？？？？", "做得好好！！", "[笑哭]", "好用心的视频！"], "2023-10-30 22:41:17"], ["video", "木羽Cheney", "职业职场", "http://www.bilibili.com/video/av623959304", "在Windows 系统上部署运行ChatGLM3-6B的第一步，正确理解项目文件的作用及下载方式", "很多小伙伴比较倾向在Windows系统上部署并实践ChatGLM3-6B模型，但往往会因为环境依赖的问题而遇到安装困难，导致无法成功部署。在这个视频中，我会给大家提供一个非常详细的ChatGLM3-6B安装和部署指南。逐步分析每个步骤，并为每个操作环节提供多种实现方法，确保大家能找到最适合自己的方案。无论是刚刚开始探索AI模型部署的新手，还是寻求更高效部署方法的经验者，这个视频一定能帮助大家在Windows上的成功部署并运行ChatGLM3-6B模型！", 3535, 33, 167, "部署, 项目, Windows, 大语言模型 (LLM), ChatGLM3", 0, ["能不能演示ubuntu22.04.4服务器版从官网安装N卡驱动，为啥我从官网安装好N卡驱动后， nvidia-smi命令回车后卡住等待一万年也没有反应", "已三连，求资料", "666[微笑][doge][妙啊]", "已三连，求资料和网盘链接", "已三连，求资料", "已三连，求资料和网盘链接", "老哥已三连，求资料", "Setting eos_token is not supported, use the default one.\\nSetting pad_token is not supported, use the default one.\\nSetting unk_token is not supported, use the default one.最后一步这三个报错是怎么一回事啊up", "这么好的up居然还没有破万粉丝。", "已三连，求资料", "三连了，up我想要个教程[呲牙]", "这个真的很详细，很赞👍🏻👍🏻👍🏻👍🏻👍🏻👍🏻👍🏻👍🏻👍🏻👍🏻👍🏻", "glm3的文件又更新了，微调的文件也都改掉了，请问up可以讲解一下最新的微调方法么", "说实在的，如果讲的再节奏快点就更好了。你这个说的太详细了，有点啰嗦，如果GIT也不会，这也不会那也不会。你这要教的也太多了....", "已三连，老哥发一下资料！[打call]", "咋还不更新？[笑哭]", "看着您教程乌班图系统部署大模型非常顺利。现在window部署老是出错，急求下部分讲解。", "我想领一下教程，已经三连[星星眼]", "能出一个纯CPU的不[大哭]", "讲得很好，谢谢分享", "哥，赶快更新[打call]", "已三连，求资料💾", "UP主的视频是我看过最好、最详细的，必须支持！", "下载后如何运行？"], "2024-01-17 22:07:16"], ["video", "ModelScope官方账号", "计算机技术", "http://www.bilibili.com/video/av963327809", "手把手教你低配置部署ChatGLM3-6b", "模型链接：https://modelscope.cn/models/ZhipuAI/chatglm3-6b/summary?from=blibli_video", 3383, 0, 226, "部署, LLM, 云端部署, 本地部署, ChatGLM3, 定制化模型部署", 0, ["Setting eos_token is not supported, use the default one.\\nSetting pad_token is not supported, use the default one.\\nSetting unk_token is not supported, use the default one.然后就没下文了，最后一步这三个报错是怎么一回事啊up", "有没有人运行python webdemo时出现OSError: Can&#39;t load tokenizer for &#39;model/chatglm-6b&#39;. If you were trying to load", "那问题来了，我这样部署了，然后怎么用呢？纯小白", "阿里的魔搭社区", "这个语言模型会道德感很高吗？比如我让他写BL文（举个例子），或者议论战争。", "确实很方便"], "2023-11-11 14:19:17"], ["video", "木羽Cheney", "职业职场", "http://www.bilibili.com/video/av708696983", "单机多卡环境下轻松部署ChatGLM3 -6B模型，合理应用与灵活管理GPU资源", "单机多卡环境是最常见的大模型部署方式，合理配置和管理GPU资源对于运行大模型至关重要。想了解如何在程序代码中灵活配置GPU资源，以及如何通过命令行直接启动和加载模型，我在本视频中给大家做了详细的讲解。此外，为了帮助大家更好地理解和实践这些技术，我还为大家准备了视频配套超详细的（34页）PDF文档，无套路，领取方式见置顶评论~", 3229, 18, 156, "GPU, 人工智能, 部署, 大模型, 大语言模型 (LLM), ChatGLM3", 0, ["666", "666", "666", "666", "666[打call][打call]", "UPUP这个可以多机多卡嘛", "666", "666", "666", "这部分内容感觉和单卡的教程一致，区别只有最后调用多卡的时候。但是我自己本机单卡可用，多卡就一直报错。", "666", "两块tesla p4速度快还是一块tesla p40块？", "666", "666", "6666", "666", "请问两张相同的卡各承担一半的参数的话，推理速度会比单卡快不？如果快的话大概快多少呢[微笑]", "666", "666", "666", "666[打call]", "666", "666", "一块1070一块4060能多卡不。。。", "666", "666", "讲得真好，感谢分享"], "2024-01-13 16:00:00"], ["video", "木羽Cheney", "职业职场", "http://www.bilibili.com/video/av708387714", "5种运行ChatGLM3-6B模型的方式！大模型本地部署必备|手把手领学，效率指数提升！", "想本地部署学习ChatGLM3-6B？本系列视频详细讲解了ChatGLM3-6B开源大模型的本地部署流程、Ubuntu系统初始化、大模型运行环境配置指南、以及五种运行方式等内容，除此之外我还给大家准备了34页超详细文档和课件，领取方式见置顶评论~", 2667, 30, 66, "科技, 人工智能, 机器学习, 深度学习, 计算机技术, OpenAI, 大模型, Agent, 大语言模型 (LLM), ChatGLM3", 0, ["请问如果是通过笔记本连主机还能用jupyter那些方式嘛，只能笔记本上ssh连主机操作[笑哭]", "想请教一下，使用cli_demo，模型加载的时候，Loading checkpoint shards:  29%|██▊       | 2/7 【00:00&lt;00:00, 19.23it/s】就推出运行了是怎么办呢？内存是16G的", "真的讲的特别好，棒[打call]", "博主您好！我想请教一下，我在运行web_demo_gradio的时候，已经改了模型地址了，但它还是会自动从huggingface上下载，然后因为连不上网站报错，该怎么办呀？", "帮大忙了！确实是关了代理还需要重启，研究一天了", "我在命令行可以进行对话正常，但是将在pycharm中打开项目后，开始一次可以用cli，web的也可以打开，然后cli的明显比在命令行环境慢很多，然后就显存溢出等等报错了，不知道为啥", "赞，必须赞，讲的非常好"], "2024-01-09 20:10:00"], ["video", "黑糖珍珠雲", "计算机技术", "http://www.bilibili.com/video/av1551029013", "chatglm3-6b部署教程（胎教版）", "还没来得及修改简介~", 2450, 0, 141, "教程, 学习, 深度学习, 编程开发, 语言模型", 0, ["@黑糖珍珠雲\xa0up求教为什么报这个错误", "16gb内存，8gb显存的4060ti 能硬带动这个模型的本地化部署吗？[笑哭]", "博主 运行的时候这个进度条一直在57％怎么解决啊 @黑糖珍珠雲", "这个问题博主你清楚怎么解决吗@黑糖珍珠雲", "安装依赖的时候报这个问题，这么解决啊@黑糖珍珠雲", "请问在pycharm上报错是为什么呢", "求助po主大佬！一直在这个地方转没有任何反应是咋回事啊？", "您好，请问这个问题您当时又遇到吗，是怎么解决的?", "大佬我用模型 运行 8bit的每次运行都有这个错 是什么原因呢", "请教一下，为什么我这会报错，本地4090，已经修改到quantize(4)了，依旧这样", "我拉到浏览器上出现这个错误，我的显存是8G的，我也已经量化到quantize（8）了，这是为什么呢？", "UP，这个怎么解决", "怎么感觉回答很奇怪呢？[喜极而泣]", "感谢分享，请教下，为啥我拉起后能进网页但是问答没反应，显卡也没动静？", "我为什么路径怎么改都不对呢？求助", "下载了最新的githubzip包和楼主提供的库，修改库地址后运行报错，请问还要修改哪里？", "这个问题是我的显存不够吗？用的是笔记本的3060", "情况：1.之前我跑起过一次，弹出了网页，但一直是run加载，加载一会没加载出来就断了，命令行里面没显示进度条。2.我多试了几次，最后一次卡死了。重启再试，就是现在这个样子。\\n咨询以下UP，这是什么原因，如何解决呀。", "请问4060TI 16GB如何修改，需要精度修改成16还是12数值？", "pycham报错 不满足软件包要求“cpm_kernels”,装也装不上，显示内存不足。代码运行报错ModuleNotFoundError: No module named &#39;readline&#39;", "Setting eos_token is not supported, use the default one.\\nSetting pad_token is not supported, use the default one.\\nSetting unk_token is not supported, use the default one.最后一步这三个报错是怎么一回事啊up", "这个需要怎么处理", "大佬能发个部署langchain+chatglm的视频吗？[星星眼]", "视频太花了，能否来个清晰版", "方便分享一下代码吗？感觉下载的代码和大佬的不一样", "nice", "🐰来支持黑🐷☁️啦"], "2024-02-25 01:16:25"], ["video", "吴恩达-机器学习", "计算机技术", "http://www.bilibili.com/video/av113049478432847", "【保姆级教程】6小时掌握开源大模型本地部署到微调，从硬件指南到ChatGLM3-6B模型部署微调实战，这应该是B站最好的大模型教程了！", "想领取超详细课件的伙伴，后台滴滴免费领取，更多与ChatGLM3及大模型相关的问题，欢迎评论区交流哦[打call]~", 1410, 21, 107, "人工智能, AI, 科技是第一生产力, 计算机视觉, 深度学习, 计算机技术, 大模型, 科技猎手, AIGC, 大模型微调, 大模型面试", 0, [], "2024-08-30 14:12:17"], ["video", "10年Java老兵转战大模型", "计算机技术", "http://www.bilibili.com/video/av113127978964818", "AI大模型-实战QLoRA微调ChatGLM3-6B", "迪哥给大家整理了一份大模型学习资料包！\\n包含：\\n1.Transformer、BERT、Huggingface三大基础模型源码资料\\n2.ChatGLM、LLM、LangChain、Lora等大语言模型预训练及微调教程和源码资料\\n3.A2024最新大模型相关面试题\\n4.大模型前沿论文", 1352, 22, 38, "教程, 模型, 学习, 实战, 人工智能, AI, 课程, AGI, 大模型, AI大模型", 0, ["up把自己整理的AI大模型资料包括AI大模型入门学习思维导图、精品AI大模型学习书籍手册、视频教程、实战学习等录播视频免费分享出来。\xa0https://b2..."], "2024-09-13 11:20:08"], ["video", "虫仔飞起来", "计算机技术", "http://www.bilibili.com/video/av113040754214210", "【实践篇】ChatGLM3-6B的安装部署、微调、训练智能客服", "ChatGLM3-6B的安装部署、微调、训练智能客服。文档、数据集、微调脚本获取方式：麻烦一键三连，评论后，我会找到评论私发源码，谢谢大家。", 124, 0, 5, "人工智能客服, AI智能客服, 怎么样用AI训练一个智能客服, 怎么训练智能客服, ChatGLM如何微调, 微调智能客服, 怎么样做AI微调", 0, ["up主可以分享一下数据集吗[喜欢]", "能用用数据集吗？"], "2024-08-29 01:14:17"]]'}]
#
#
# for doc in raw_docs:
#     print(doc["keyword"])
#     print(doc["formatted_videos"])
#     print("------------")
#
#     print(doc["data_to_write"])
#     print("------------")


raw = [{'result_type': 'tips', 'data': []}, {'result_type': 'brand_ad', 'data': []},
       {'result_type': 'esports', 'data': []}, {'result_type': 'activity', 'data': []},
       {'result_type': 'web_game', 'data': []}, {'result_type': 'card', 'data': []},
       {'result_type': 'media_bangumi', 'data': []}, {'result_type': 'media_ft', 'data': []},
       {'result_type': 'bili_user', 'data': []}, {'result_type': 'user', 'data': []},
       {'result_type': 'star', 'data': []}, {'result_type': 'video', 'data': [
        {'type': 'video', 'id': 1002416941, 'author': '超想敲代码', 'mid': 272222941, 'typeid': '231',
         'typename': '计算机技术', 'arcurl': 'http://www.bilibili.com/video/av1002416941', 'aid': 1002416941,
         'bvid': 'BV1Cx4y1m7Gd',
         'title': '部署微调<em class="keyword">ChatGlm3</em>-<em class="keyword">6B大模型</em>【小白0到1】',
         'description': '手把手教学如何部署ChatGlm3大模型、使用LlaMa-Factory进行大模型微调。0代码部署、微调大模型，白嫖服务器，小白也能听得懂学得会！！！\n笔记链接：http://t.csdnimg.cn/ifaH5',
         'arcrank': '0', 'pic': '//i0.hdslb.com/bfs/archive/f6c02cb1b5be59e34275567e448ec9966184bd8a.jpg',
         'play': 21236, 'video_review': 25, 'favorites': 1039,
         'tag': '训练,AI,NLP,小白教程,大模型,chatglm,大模型微调,大模型部署,llama factory,loar微调', 'review': 533,
         'pubdate': 1711558909, 'senddate': 1712046485, 'duration': '40:20', 'badgepay': False,
         'hit_columns': ['title', 'description', 'author', 'tag'], 'view_type': '', 'is_pay': 0, 'is_union_video': 0,
         'rec_tags': None, 'new_rec_tags': [], 'rank_score': 172217254, 'like': 384,
         'upic': 'https://i1.hdslb.com/bfs/face/8e2e7246d8104ff3dbb29cbc783d6a4a5e41f53c.jpg', 'corner': '',
         'cover': '', 'desc': '', 'url': '', 'rec_reason': '', 'danmaku': 25, 'biz_data': None, 'is_charge_video': 0,
         'vt': 0, 'enable_vt': 0, 'vt_display': '', 'subtitle': '', 'episode_count_text': '', 'release_status': 0,
         'is_intervene': 0, 'area': 0, 'style': 0, 'cate_name': '', 'is_live_room_inline': 0, 'live_status': 0,
         'live_time': '', 'online': 0, 'rank_index': 1, 'rank_offset': 1, 'roomid': 0, 'short_id': 0, 'spread_id': 0,
         'tags': '', 'uface': '', 'uid': 0, 'uname': '', 'user_cover': '', 'parent_area_id': 0, 'parent_area_name': '',
         'watched_show': None},
        {'type': 'video', 'id': 241845815, 'author': '木羽Cheney', 'mid': 3537113897241540, 'typeid': '209',
         'typename': '职业职场', 'arcurl': 'http://www.bilibili.com/video/av241845815', 'aid': 241845815,
         'bvid': 'BV1ce411J7nZ',
         'title': '【保姆级教程】6小时掌握开源<em class="keyword">大模型</em>本地部署到微调，从硬件指南到<em class="keyword">ChatGLM3</em>-<em class="keyword">6B模型</em>部署微调实战｜逐帧详解｜直达技术底层',
         'description': '公开课节选自付费课程《大模型技术实战课》，2024最新版2期课程现已上线！6大主流大模型+14项大模型工具+5大热门方向企业级实战项目，零基础直达大模型企业级应用！【付费课程信息】添加+🌏：littlecat_1207，回复“大模型”详询哦～',
         'arcrank': '0', 'pic': '//i0.hdslb.com/bfs/archive/a8a96d67fd033ad35b3699108be2e8b6cf25087e.png',
         'play': 144936, 'video_review': 1453, 'favorites': 9939,
         'tag': '模型,人工智能,AI,部署,微调,深度学习,OpenAI,本地部署,大语言模型 (LLM),ChatGLM3', 'review': 2581,
         'pubdate': 1706355351, 'senddate': 1710933841, 'duration': '384:41', 'badgepay': False,
         'hit_columns': ['title', 'description', 'tag'], 'view_type': '', 'is_pay': 0, 'is_union_video': 0,
         'rec_tags': None, 'new_rec_tags': [], 'rank_score': 115116645, 'like': 3150,
         'upic': 'https://i0.hdslb.com/bfs/face/6ef695686f04ea4b81846c64a507607d1fea8a89.jpg', 'corner': '',
         'cover': '', 'desc': '', 'url': '', 'rec_reason': '', 'danmaku': 1453, 'biz_data': None, 'is_charge_video': 0,
         'vt': 0, 'enable_vt': 0, 'vt_display': '', 'subtitle': '', 'episode_count_text': '', 'release_status': 0,
         'is_intervene': 0, 'area': 0, 'style': 0, 'cate_name': '', 'is_live_room_inline': 0, 'live_status': 0,
         'live_time': '', 'online': 0, 'rank_index': 2, 'rank_offset': 2, 'roomid': 0, 'short_id': 0, 'spread_id': 0,
         'tags': '', 'uface': '', 'uid': 0, 'uname': '', 'user_cover': '', 'parent_area_id': 0, 'parent_area_name': '',
         'watched_show': None},
        {'type': 'video', 'id': 1753100101, 'author': '编程分享录', 'mid': 674558378, 'typeid': '231',
         'typename': '计算机技术', 'arcurl': 'http://www.bilibili.com/video/av1753100101', 'aid': 1753100101,
         'bvid': 'BV1yx421m7tn',
         'title': '【<em class="keyword">大模型</em>微调】<em class="keyword">ChatGLM3</em>-<em class="keyword">6b大模型</em>微调 | 基于开源的<em class="keyword">大模型</em>的微调 | 使用自己的数据集来微调<em class="keyword">大模型</em> | 垂直领域<em class="keyword">大模型</em> | lora微调<em class="keyword">大模型</em>',
         'description': '【大模型微调】ChatGLM3-6b大模型微调 | 基于开源的大模型的微调 | 使用自己的数据集来微调大模型 | 垂直领域大模型 | lora微调大模型\n本视频中使用的是开源的大模型ChatGLM3，微调脚本为官方提供\n数据集可以自己制作，然后微调成垂直领域的大模型\n更多内容欢迎关注我',
         'arcrank': '0', 'pic': '//i2.hdslb.com/bfs/archive/ef58b014e4849f04f0d3ca10e963fe081e8e8a88.jpg', 'play': 5044,
         'video_review': 1, 'favorites': 375,
         'tag': '微调,大模型,lora,LLM,ChatGPT,大语言模型 (LLM),lora微调大模型,本地专有大模型', 'review': 62,
         'pubdate': 1712979794, 'senddate': 1712979794, 'duration': '32:1', 'badgepay': False,
         'hit_columns': ['title', 'description', 'tag'], 'view_type': '', 'is_pay': 0, 'is_union_video': 0,
         'rec_tags': None, 'new_rec_tags': [], 'rank_score': 111602141, 'like': 122,
         'upic': 'https://i2.hdslb.com/bfs/face/bdba0b71b2f4302c2086283d86e9bd13e95cfa74.jpg', 'corner': '',
         'cover': '', 'desc': '', 'url': '', 'rec_reason': '', 'danmaku': 1, 'biz_data': None, 'is_charge_video': 0,
         'vt': 0, 'enable_vt': 0, 'vt_display': '', 'subtitle': '', 'episode_count_text': '', 'release_status': 0,
         'is_intervene': 0, 'area': 0, 'style': 0, 'cate_name': '', 'is_live_room_inline': 0, 'live_status': 0,
         'live_time': '', 'online': 0, 'rank_index': 3, 'rank_offset': 3, 'roomid': 0, 'short_id': 0, 'spread_id': 0,
         'tags': '', 'uface': '', 'uid': 0, 'uname': '', 'user_cover': '', 'parent_area_id': 0, 'parent_area_name': '',
         'watched_show': None},
        {'type': 'video', 'id': 401497353, 'author': 'ChatGLM', 'mid': 3493270982232856, 'typeid': '231',
         'typename': '计算机技术', 'arcurl': 'http://www.bilibili.com/video/av401497353', 'aid': 401497353,
         'bvid': 'BV1fd4y1Z7Y5',
         'title': '【官方教程】<em class="keyword">ChatGLM</em>-<em class="keyword">6B</em> 微调：P-Tuning，LoRA，Full parameter',
         'description': '我们详细介绍了GLM的技术背景，以及ChatGLM-6B的微调方案，包括P-tuning、LoRA、Full-Parameter等，并针对提问提供了详细的回复。\n\n报告文件下载链接: https://pan.baidu.com/s/1CKS5yBz6-GN_J7UB_wxguw?pwd=g26m 提取码: g26m',
         'arcrank': '0', 'pic': '//i0.hdslb.com/bfs/archive/2cda769b22475cd6497d09aca1cd0cc3f3d19944.jpg',
         'play': 114165, 'video_review': 255, 'favorites': 8854,
         'tag': '教程,官方,清华,经验分享,大模型,科技猎手2023,chatglm,这就是AIGC,智谱AI', 'review': 362,
         'pubdate': 1684735924, 'senddate': 1684898768, 'duration': '78:45', 'badgepay': False,
         'hit_columns': ['title', 'description', 'author', 'tag'], 'view_type': '', 'is_pay': 0, 'is_union_video': 0,
         'rec_tags': None, 'new_rec_tags': [], 'rank_score': 105799013, 'like': 3406,
         'upic': 'https://i1.hdslb.com/bfs/face/ed1c8faa182cd66788af5b988d78570bdcee0780.jpg', 'corner': '',
         'cover': '', 'desc': '', 'url': '', 'rec_reason': '', 'danmaku': 255, 'biz_data': None, 'is_charge_video': 0,
         'vt': 0, 'enable_vt': 0, 'vt_display': '', 'subtitle': '', 'episode_count_text': '', 'release_status': 0,
         'is_intervene': 0, 'area': 0, 'style': 0, 'cate_name': '', 'is_live_room_inline': 0, 'live_status': 0,
         'live_time': '', 'online': 0, 'rank_index': 4, 'rank_offset': 4, 'roomid': 0, 'short_id': 0, 'spread_id': 0,
         'tags': '', 'uface': '', 'uid': 0, 'uname': '', 'user_cover': '', 'parent_area_id': 0, 'parent_area_name': '',
         'watched_show': None},
        {'type': 'video', 'id': 827358365, 'author': '九天Hector', 'mid': 385842994, 'typeid': '122',
         'typename': '野生技能协会', 'arcurl': 'http://www.bilibili.com/video/av827358365', 'aid': 827358365,
         'bvid': 'BV1Xg4y1N7kM',
         'title': '【入门】开源<em class="keyword">大模型</em>生态与<em class="keyword">ChatGLM</em>-<em class="keyword">6B大模型</em>介绍｜最强中文<em class="keyword">大模型</em>GLM介绍｜LLM开源<em class="keyword">大模型</em>概览',
         'description': '大模型入门系列教程第二弹：《开源大模型生态与ChatGLM-6B大模型介绍》来啦～视频将为大家详细介绍目前开源大模型生态，并重点介绍目前中文领域最强大模型GLM的技术生态，包括GLM-130B、ChatGLM-6B、visualGLM等，帮助大家快速建立技术认知，领跑大模型时代～\n公开课资料领取：添加客服VX：littlecat_1207，回复“LLM”即可免费领取哦～\n公开课视频节选自《大模型与AIGC技术实战》课程，完整版课为付费课程，课程包含提示工程技术、AIGC实战、大模型部署与API调用方法、L',
         'arcrank': '0', 'pic': '//i1.hdslb.com/bfs/archive/4907f2a28044d0d36e9a90a8ae18746145d6ac98.jpg',
         'play': 17723, 'video_review': 83, 'favorites': 637,
         'tag': '人工智能,机器学习,深度学习,OpenAI,GPT,GLM,LLM,ChatGPT,大语言模型,ChatGLM', 'review': 8,
         'pubdate': 1686822234, 'senddate': 1686828099, 'duration': '33:35', 'badgepay': False,
         'hit_columns': ['title', 'description', 'tag'], 'view_type': '', 'is_pay': 0, 'is_union_video': 0,
         'rec_tags': None, 'new_rec_tags': [], 'rank_score': 104681013, 'like': 575,
         'upic': 'https://i1.hdslb.com/bfs/face/667a093664817884057caa9c057cd16a91cde202.jpg', 'corner': '',
         'cover': '', 'desc': '', 'url': '', 'rec_reason': '', 'danmaku': 83, 'biz_data': None, 'is_charge_video': 0,
         'vt': 0, 'enable_vt': 0, 'vt_display': '', 'subtitle': '', 'episode_count_text': '', 'release_status': 0,
         'is_intervene': 0, 'area': 0, 'style': 0, 'cate_name': '', 'is_live_room_inline': 0, 'live_status': 0,
         'live_time': '', 'online': 0, 'rank_index': 5, 'rank_offset': 5, 'roomid': 0, 'short_id': 0, 'spread_id': 0,
         'tags': '', 'uface': '', 'uid': 0, 'uname': '', 'user_cover': '', 'parent_area_id': 0, 'parent_area_name': '',
         'watched_show': None},
        {'type': 'video', 'id': 238452117, 'author': '木羽Cheney', 'mid': 3537113897241540, 'typeid': '209',
         'typename': '职业职场', 'arcurl': 'http://www.bilibili.com/video/av238452117', 'aid': 238452117,
         'bvid': 'BV1je411U7Cv',
         'title': '<em class="keyword">ChatGLM3</em>-<em class="keyword">6B模型</em>本地部署必备！零门槛Ubuntu系统初始化配置教程|逐步带你完成配置|为<em class="keyword">大模型</em>运行打下基础！',
         'description': '想本地部署学习ChatGLM3-6B？本系列视频详细讲解了ChatGLM3-6B开源大模型的本地部署流程、Ubuntu系统初始化、大模型运行环境配置指南、以及五种运行方式等内容，除此之外我还给大家准备了34页超详细文档和课件，领取方式见置顶评论~',
         'arcrank': '0', 'pic': '//i0.hdslb.com/bfs/archive/92a499760ae300831af02324bf0d71f0960a999f.jpg', 'play': 5153,
         'video_review': 38, 'favorites': 258,
         'tag': '科技,人工智能,机器学习,深度学习,计算机技术,OpenAI,大模型,Agent,大语言模型 (LLM),ChatGLM3',
         'review': 68, 'pubdate': 1704710950, 'senddate': 1707005590, 'duration': '23:34', 'badgepay': False,
         'hit_columns': ['title', 'description', 'tag'], 'view_type': '', 'is_pay': 0, 'is_union_video': 0,
         'rec_tags': None, 'new_rec_tags': [], 'rank_score': 104542239, 'like': 78,
         'upic': 'https://i0.hdslb.com/bfs/face/6ef695686f04ea4b81846c64a507607d1fea8a89.jpg', 'corner': '',
         'cover': '', 'desc': '', 'url': '', 'rec_reason': '', 'danmaku': 38, 'biz_data': None, 'is_charge_video': 0,
         'vt': 0, 'enable_vt': 0, 'vt_display': '', 'subtitle': '', 'episode_count_text': '', 'release_status': 0,
         'is_intervene': 0, 'area': 0, 'style': 0, 'cate_name': '', 'is_live_room_inline': 0, 'live_status': 0,
         'live_time': '', 'online': 0, 'rank_index': 6, 'rank_offset': 6, 'roomid': 0, 'short_id': 0, 'spread_id': 0,
         'tags': '', 'uface': '', 'uid': 0, 'uname': '', 'user_cover': '', 'parent_area_id': 0, 'parent_area_name': '',
         'watched_show': None},
        {'type': 'video', 'id': 407925945, 'author': 'AI技术大本营', 'mid': 688174628, 'typeid': '230',
         'typename': '软件应用', 'arcurl': 'http://www.bilibili.com/video/av407925945', 'aid': 407925945,
         'bvid': 'BV1pG411X7XP',
         'title': '<em class="keyword">ChatGLM3</em>-<em class="keyword">6B大</em>语言<em class="keyword">模型</em>本地一键整合包下载地址',
         'description': 'ChatGLM3-6B的项目github地址：https://github.com/THUDM/ChatGLM3\nChatGLM3-6B大语言模型本地一键整合包下载地址：解压密码 www.aibl.vip\n 链接：https://pan.baidu.com/s/1zqOS_BkUbo8h7cXNxotypA?pwd=09n1 \n 提取码：09n1 \n整合包源下载地址：https://www.aibl.vip/thread-159-1-1.html',
         'arcrank': '0', 'pic': '//i1.hdslb.com/bfs/archive/92d691990f905b8a70f1961b20518c42fdb83e0c.jpg', 'play': 5982,
         'video_review': 2, 'favorites': 267, 'tag': '本地,语言模型,大语言模型,ChatGLM3,ChatGLM3-6B', 'review': 66,
         'pubdate': 1698893923, 'senddate': 1699366772, 'duration': '1:37', 'badgepay': False,
         'hit_columns': ['title', 'description', 'tag'], 'view_type': '', 'is_pay': 0, 'is_union_video': 0,
         'rec_tags': None, 'new_rec_tags': [], 'rank_score': 104078225, 'like': 111,
         'upic': 'https://i2.hdslb.com/bfs/face/608f762844b725e5a241212cb0b944bab0e5b8e9.jpg', 'corner': '',
         'cover': '', 'desc': '', 'url': '', 'rec_reason': '', 'danmaku': 2, 'biz_data': None, 'is_charge_video': 0,
         'vt': 0, 'enable_vt': 0, 'vt_display': '', 'subtitle': '', 'episode_count_text': '', 'release_status': 0,
         'is_intervene': 0, 'area': 0, 'style': 0, 'cate_name': '', 'is_live_room_inline': 0, 'live_status': 0,
         'live_time': '', 'online': 0, 'rank_index': 7, 'rank_offset': 7, 'roomid': 0, 'short_id': 0, 'spread_id': 0,
         'tags': '', 'uface': '', 'uid': 0, 'uname': '', 'user_cover': '', 'parent_area_id': 0, 'parent_area_name': '',
         'watched_show': None},
        {'type': 'video', 'id': 1551029013, 'author': '黑糖珍珠雲', 'mid': 10845739, 'typeid': '231',
         'typename': '计算机技术', 'arcurl': 'http://www.bilibili.com/video/av1551029013', 'aid': 1551029013,
         'bvid': 'BV1ky421z7GE',
         'title': '<em class="keyword">chatglm3</em>-<em class="keyword">6b</em>部署教程（胎教版）',
         'description': '还没来得及修改简介~', 'arcrank': '0',
         'pic': '//i0.hdslb.com/bfs/archive/bcd1135f15ecede08f2ed5b8cc36b97a98f20bf1.jpg', 'play': 2484,
         'video_review': 0, 'favorites': 143, 'tag': '教程,学习,深度学习,编程开发,语言模型', 'review': 86,
         'pubdate': 1708794985, 'senddate': 1709134531, 'duration': '47:28', 'badgepay': False,
         'hit_columns': ['title', 'tag'], 'view_type': '', 'is_pay': 0, 'is_union_video': 0, 'rec_tags': None,
         'new_rec_tags': [], 'rank_score': 103794296, 'like': 64,
         'upic': 'https://i1.hdslb.com/bfs/face/81561eadf554d2c0a9bcd84b77081801ae396de6.jpg', 'corner': '',
         'cover': '', 'desc': '', 'url': '', 'rec_reason': '', 'danmaku': 0, 'biz_data': None, 'is_charge_video': 0,
         'vt': 0, 'enable_vt': 0, 'vt_display': '', 'subtitle': '', 'episode_count_text': '', 'release_status': 0,
         'is_intervene': 0, 'area': 0, 'style': 0, 'cate_name': '', 'is_live_room_inline': 0, 'live_status': 0,
         'live_time': '', 'online': 0, 'rank_index': 8, 'rank_offset': 8, 'roomid': 0, 'short_id': 0, 'spread_id': 0,
         'tags': '', 'uface': '', 'uid': 0, 'uname': '', 'user_cover': '', 'parent_area_id': 0, 'parent_area_name': '',
         'watched_show': None},
        {'type': 'video', 'id': 708746434, 'author': '木羽Cheney', 'mid': 3537113897241540, 'typeid': '209',
         'typename': '职业职场', 'arcurl': 'http://www.bilibili.com/video/av708746434', 'aid': 708746434,
         'bvid': 'BV1uQ4y1L7PH',
         'title': '30分钟学会运行<em class="keyword">ChatGLM3</em>-<em class="keyword">6B模型</em>的P-Turning V2高效微调及全量微调代码',
         'description': '工作中急需微调Chat GLM3-6B模型，却不懂微调原理怎么办？这个视频中，即使大家对大模型微调的原理还不太了解，也能快速开始实际操作。我会帮助大家通俗的理解目前主流的高效微调方法并着重介绍如何快速运行ChatGLM3官方支持的P-Turning v2微调技术。此外，为了帮助大家更好地理解和实践这些技术，我还为大家准备了视频配套超详细的（34页）PDF文档，无套路，领取方式见置顶评论~',
         'arcrank': '0', 'pic': '//i1.hdslb.com/bfs/archive/8deb27023951be8181279d7a2ef7fe70f9cd25db.jpg', 'play': 8608,
         'video_review': 85, 'favorites': 642, 'tag': '高效,微调,大语言模型 (LLM),ChatGLM3', 'review': 228,
         'pubdate': 1705147200, 'senddate': 1705984805, 'duration': '37:2', 'badgepay': False,
         'hit_columns': ['title', 'description', 'tag'], 'view_type': '', 'is_pay': 0, 'is_union_video': 0,
         'rec_tags': None, 'new_rec_tags': [], 'rank_score': 103760272, 'like': 217,
         'upic': 'https://i0.hdslb.com/bfs/face/6ef695686f04ea4b81846c64a507607d1fea8a89.jpg', 'corner': '',
         'cover': '', 'desc': '', 'url': '', 'rec_reason': '', 'danmaku': 85, 'biz_data': None, 'is_charge_video': 0,
         'vt': 0, 'enable_vt': 0, 'vt_display': '', 'subtitle': '', 'episode_count_text': '', 'release_status': 0,
         'is_intervene': 0, 'area': 0, 'style': 0, 'cate_name': '', 'is_live_room_inline': 0, 'live_status': 0,
         'live_time': '', 'online': 0, 'rank_index': 9, 'rank_offset': 9, 'roomid': 0, 'short_id': 0, 'spread_id': 0,
         'tags': '', 'uface': '', 'uid': 0, 'uname': '', 'user_cover': '', 'parent_area_id': 0, 'parent_area_name': '',
         'watched_show': None},
        {'type': 'video', 'id': 747967526, 'author': 'ChatGLM', 'mid': 3493270982232856, 'typeid': '231',
         'typename': '计算机技术', 'arcurl': 'http://www.bilibili.com/video/av747967526', 'aid': 747967526,
         'bvid': 'BV1uC4y1J7yA',
         'title': '【官方教程】<em class="keyword">ChatGLM3</em>-<em class="keyword">6B</em> 部署和微调（Function Call、Code Interpreter、Agent）',
         'description': 'ChatGLM3 技术文档：https://zhipu-ai.feishu.cn/wiki/YInmwPmyii67VRkzU3BchPNzncg\n\n模型仓库：https://github.com/THUDM/ChatGLM3\n\n模型下载：\nHF：https://huggingface.co/THUDM\n魔搭：https://modelscope.cn/models/ZhipuAI\n\n文件下载：https://pan.baidu.com/s/14NtD9A3Ls3VkuIPy8Iar8Q?pwd=na5c',
         'arcrank': '0', 'pic': '//i1.hdslb.com/bfs/archive/0dbd4eb239aa469daea7913f4c60f0c8ef0bec88.jpg',
         'play': 102161, 'video_review': 182, 'favorites': 5953,
         'tag': '人工智能,清华大学,微调,大模型,agent,chatglm,智谱AI', 'review': 458, 'pubdate': 1698850951,
         'senddate': 1703912205, 'duration': '57:9', 'badgepay': False,
         'hit_columns': ['title', 'description', 'author', 'tag'], 'view_type': '', 'is_pay': 0, 'is_union_video': 0,
         'rec_tags': None, 'new_rec_tags': [], 'rank_score': 103651090, 'like': 2358,
         'upic': 'https://i1.hdslb.com/bfs/face/ed1c8faa182cd66788af5b988d78570bdcee0780.jpg', 'corner': '',
         'cover': '', 'desc': '', 'url': '', 'rec_reason': '', 'danmaku': 182, 'biz_data': None, 'is_charge_video': 0,
         'vt': 0, 'enable_vt': 0, 'vt_display': '', 'subtitle': '', 'episode_count_text': '', 'release_status': 0,
         'is_intervene': 0, 'area': 0, 'style': 0, 'cate_name': '', 'is_live_room_inline': 0, 'live_status': 0,
         'live_time': '', 'online': 0, 'rank_index': 10, 'rank_offset': 10, 'roomid': 0, 'short_id': 0, 'spread_id': 0,
         'tags': '', 'uface': '', 'uid': 0, 'uname': '', 'user_cover': '', 'parent_area_id': 0, 'parent_area_name': '',
         'watched_show': None},
        {'type': 'video', 'id': 113174787460517, 'author': '大模型入门教程', 'mid': 1569066411, 'typeid': '122',
         'typename': '野生技能协会', 'arcurl': 'http://www.bilibili.com/video/av113174787460517',
         'aid': 113174787460517, 'bvid': 'BV1J2tkeSEzK',
         'title': '<em class="keyword">ChatGLM</em>-<em class="keyword">6B模型</em>部署与微调教程，<em class="keyword">大模型</em>训练流程及原理+微调容易踩的坑全详解！从<em class="keyword">模型</em>架构到实际应用，（Function Call、Code Interpr',
         'description': '', 'arcrank': '0',
         'pic': '//i0.hdslb.com/bfs/archive/7c90b5806ecb9fe23923f2700b0dd2b9f084e473.jpg', 'play': 670,
         'video_review': 92, 'favorites': 51, 'tag': '模型,人工智能,AI,大模型,AI入门,大模型入门,大模型教程',
         'review': 19, 'pubdate': 1726910405, 'senddate': 1726910405, 'duration': '62:53', 'badgepay': False,
         'hit_columns': ['title', 'author', 'tag'], 'view_type': '', 'is_pay': 0, 'is_union_video': 0, 'rec_tags': None,
         'new_rec_tags': [], 'rank_score': 103603959, 'like': 18,
         'upic': 'https://i0.hdslb.com/bfs/face/260d2004cecc111a68fc2e6e5a2edd1ef273ce32.jpg', 'corner': '',
         'cover': '', 'desc': '', 'url': '', 'rec_reason': '', 'danmaku': 92, 'biz_data': None, 'is_charge_video': 0,
         'vt': 0, 'enable_vt': 0, 'vt_display': '', 'subtitle': '', 'episode_count_text': '', 'release_status': 0,
         'is_intervene': 0, 'area': 0, 'style': 0, 'cate_name': '', 'is_live_room_inline': 0, 'live_status': 0,
         'live_time': '', 'online': 0, 'rank_index': 11, 'rank_offset': 11, 'roomid': 0, 'short_id': 0, 'spread_id': 0,
         'tags': '', 'uface': '', 'uid': 0, 'uname': '', 'user_cover': '', 'parent_area_id': 0, 'parent_area_name': '',
         'watched_show': None},
        {'type': 'video', 'id': 1502084615, 'author': '紫陌垂杨洛西', 'mid': 107645594, 'typeid': '231',
         'typename': '计算机技术', 'arcurl': 'http://www.bilibili.com/video/av1502084615', 'aid': 1502084615,
         'bvid': 'BV1YD42177VE', 'title': '<em class="keyword">chatglm3模型</em>本地部署及微调',
         'description': '最新的chatglm3模型部署和llora微调，因为chatglm3官网代码有修改，记录下现在的模型微调和踩过的坑。',
         'arcrank': '0', 'pic': '//i1.hdslb.com/bfs/archive/de4a9555e97933992947e7acb9617ae04d897665.png', 'play': 4981,
         'video_review': 6, 'favorites': 309, 'tag': '微调,大模型,本地部署,lora微调,chagglm3', 'review': 87,
         'pubdate': 1711181772, 'senddate': 1712490535, 'duration': '30:45', 'badgepay': False,
         'hit_columns': ['title', 'description', 'tag'], 'view_type': '', 'is_pay': 0, 'is_union_video': 0,
         'rec_tags': None, 'new_rec_tags': [], 'rank_score': 103272500, 'like': 90,
         'upic': 'https://i2.hdslb.com/bfs/face/269f1f31c8842a4525957476a9f02bad77056f64.jpg', 'corner': '',
         'cover': '', 'desc': '', 'url': '', 'rec_reason': '', 'danmaku': 6, 'biz_data': None, 'is_charge_video': 0,
         'vt': 0, 'enable_vt': 0, 'vt_display': '', 'subtitle': '', 'episode_count_text': '', 'release_status': 0,
         'is_intervene': 0, 'area': 0, 'style': 0, 'cate_name': '', 'is_live_room_inline': 0, 'live_status': 0,
         'live_time': '', 'online': 0, 'rank_index': 12, 'rank_offset': 12, 'roomid': 0, 'short_id': 0, 'spread_id': 0,
         'tags': '', 'uface': '', 'uid': 0, 'uname': '', 'user_cover': '', 'parent_area_id': 0, 'parent_area_name': '',
         'watched_show': None},
        {'type': 'video', 'id': 113127978964818, 'author': '10年Java老兵转战大模型', 'mid': 1946337667, 'typeid': '231',
         'typename': '计算机技术', 'arcurl': 'http://www.bilibili.com/video/av113127978964818', 'aid': 113127978964818,
         'bvid': 'BV1jw4te8ETy',
         'title': 'AI<em class="keyword">大模型</em>-实战QLoRA微调<em class="keyword">ChatGLM3</em>-<em class="keyword">6B</em>',
         'description': '迪哥给大家整理了一份大模型学习资料包！\n包含：\n1.Transformer、BERT、Huggingface三大基础模型源码资料\n2.ChatGLM、LLM、LangChain、Lora等大语言模型预训练及微调教程和源码资料\n3.A2024最新大模型相关面试题\n4.大模型前沿论文',
         'arcrank': '0', 'pic': '//i1.hdslb.com/bfs/archive/b610233582e1e45ae8c8449ab38e057f42032a54.jpg', 'play': 1423,
         'video_review': 23, 'favorites': 39, 'tag': '教程,模型,学习,实战,人工智能,AI,课程,AGI,大模型,AI大模型',
         'review': 1, 'pubdate': 1726197608, 'senddate': 1728179707, 'duration': '152:49', 'badgepay': False,
         'hit_columns': ['title', 'description', 'author', 'tag'], 'view_type': '', 'is_pay': 0, 'is_union_video': 0,
         'rec_tags': None, 'new_rec_tags': [], 'rank_score': 103001871, 'like': 30,
         'upic': 'https://i1.hdslb.com/bfs/face/73f5c2df517b3c680f23ae4b6a5e1b7dc171cbed.jpg', 'corner': '',
         'cover': '', 'desc': '', 'url': '', 'rec_reason': '', 'danmaku': 23, 'biz_data': None, 'is_charge_video': 0,
         'vt': 0, 'enable_vt': 0, 'vt_display': '', 'subtitle': '', 'episode_count_text': '', 'release_status': 0,
         'is_intervene': 0, 'area': 0, 'style': 0, 'cate_name': '', 'is_live_room_inline': 0, 'live_status': 0,
         'live_time': '', 'online': 0, 'rank_index': 13, 'rank_offset': 13, 'roomid': 0, 'short_id': 0, 'spread_id': 0,
         'tags': '', 'uface': '', 'uid': 0, 'uname': '', 'user_cover': '', 'parent_area_id': 0, 'parent_area_name': '',
         'watched_show': None},
        {'type': 'video', 'id': 365368404, 'author': '会算法的猫', 'mid': 567541406, 'typeid': '21', 'typename': '日常',
         'arcurl': 'http://www.bilibili.com/video/av365368404', 'aid': 365368404, 'bvid': 'BV1X94y157Ko',
         'title': '<em class="keyword">大模型chatglm3</em>-<em class="keyword">6b</em>之开外挂',
         'description': '大模型agent', 'arcrank': '0',
         'pic': '//i1.hdslb.com/bfs/archive/54f6830cebdeec63f5debedf890216bad410d7c6.jpg', 'play': 4155,
         'video_review': 0, 'favorites': 184, 'tag': 'NLP,大模型,Agent,chatglm3', 'review': 20, 'pubdate': 1698676877,
         'senddate': 1698693121, 'duration': '9:7', 'badgepay': False, 'hit_columns': ['title', 'description', 'tag'],
         'view_type': '', 'is_pay': 0, 'is_union_video': 0, 'rec_tags': None, 'new_rec_tags': [],
         'rank_score': 102581309, 'like': 70,
         'upic': 'https://i2.hdslb.com/bfs/face/e686268636fb12b4a1b2877505b2c2b007ce8f06.jpg', 'corner': '',
         'cover': '', 'desc': '', 'url': '', 'rec_reason': '', 'danmaku': 0, 'biz_data': None, 'is_charge_video': 0,
         'vt': 0, 'enable_vt': 0, 'vt_display': '', 'subtitle': '', 'episode_count_text': '', 'release_status': 0,
         'is_intervene': 0, 'area': 0, 'style': 0, 'cate_name': '', 'is_live_room_inline': 0, 'live_status': 0,
         'live_time': '', 'online': 0, 'rank_index': 14, 'rank_offset': 14, 'roomid': 0, 'short_id': 0, 'spread_id': 0,
         'tags': '', 'uface': '', 'uid': 0, 'uname': '', 'user_cover': '', 'parent_area_id': 0, 'parent_area_name': '',
         'watched_show': None},
        {'type': 'video', 'id': 708387714, 'author': '木羽Cheney', 'mid': 3537113897241540, 'typeid': '209',
         'typename': '职业职场', 'arcurl': 'http://www.bilibili.com/video/av708387714', 'aid': 708387714,
         'bvid': 'BV1wQ4y1j7uT',
         'title': '5种运行<em class="keyword">ChatGLM3</em>-<em class="keyword">6B模型</em>的方式！<em class="keyword">大模型</em>本地部署必备|手把手领学，效率指数提升！',
         'description': '想本地部署学习ChatGLM3-6B？本系列视频详细讲解了ChatGLM3-6B开源大模型的本地部署流程、Ubuntu系统初始化、大模型运行环境配置指南、以及五种运行方式等内容，除此之外我还给大家准备了34页超详细文档和课件，领取方式见置顶评论~',
         'arcrank': '0', 'pic': '//i2.hdslb.com/bfs/archive/3c650ff25fba2ff9bd462d18f136c24433118f09.jpg', 'play': 2669,
         'video_review': 30, 'favorites': 66,
         'tag': '科技,人工智能,机器学习,深度学习,计算机技术,OpenAI,大模型,Agent,大语言模型 (LLM),ChatGLM3',
         'review': 12, 'pubdate': 1704802200, 'senddate': 1704802202, 'duration': '15:22', 'badgepay': False,
         'hit_columns': ['title', 'description', 'tag'], 'view_type': '', 'is_pay': 0, 'is_union_video': 0,
         'rec_tags': None, 'new_rec_tags': [], 'rank_score': 102155836, 'like': 28,
         'upic': 'https://i0.hdslb.com/bfs/face/6ef695686f04ea4b81846c64a507607d1fea8a89.jpg', 'corner': '',
         'cover': '', 'desc': '', 'url': '', 'rec_reason': '', 'danmaku': 30, 'biz_data': None, 'is_charge_video': 0,
         'vt': 0, 'enable_vt': 0, 'vt_display': '', 'subtitle': '', 'episode_count_text': '', 'release_status': 0,
         'is_intervene': 0, 'area': 0, 'style': 0, 'cate_name': '', 'is_live_room_inline': 0, 'live_status': 0,
         'live_time': '', 'online': 0, 'rank_index': 15, 'rank_offset': 15, 'roomid': 0, 'short_id': 0, 'spread_id': 0,
         'tags': '', 'uface': '', 'uid': 0, 'uname': '', 'user_cover': '', 'parent_area_id': 0, 'parent_area_name': '',
         'watched_show': None},
        {'type': 'video', 'id': 113201798711974, 'author': '大模型老于', 'mid': 3546755297708147, 'typeid': '231',
         'typename': '计算机技术', 'arcurl': 'http://www.bilibili.com/video/av113201798711974', 'aid': 113201798711974,
         'bvid': 'BV1TKxLeLE8W',
         'title': '【B站首推】2小时掌握<em class="keyword">ChatGLM</em>-4本地部署-微调-实战，原理讲解+代码解析，超详细，LLM_<em class="keyword">大模型</em>_微调_-Agent_RAG',
         'description': 'GLM4大模型教程来啦！深度介绍国产大模型天花板GLM4模型特性，零基础入门，高效掌握GLM4模型API调用方法',
         'arcrank': '0', 'pic': '//i1.hdslb.com/bfs/archive/e9255bee2a76ab9c11d47d65f256eac5ed18db3c.png', 'play': 7772,
         'video_review': 153, 'favorites': 261, 'tag': '模型,人工智能,AI,微调,GPT,大模型,GLM,openAI,模型部署,智普',
         'review': 50, 'pubdate': 1727340348, 'senddate': 1727340348, 'duration': '59:23', 'badgepay': False,
         'hit_columns': ['title', 'description', 'author', 'tag'], 'view_type': '', 'is_pay': 0, 'is_union_video': 0,
         'rec_tags': None, 'new_rec_tags': [], 'rank_score': 101928152, 'like': 173,
         'upic': 'https://i2.hdslb.com/bfs/face/845295f684f173997f0c812517084e61881c5e0a.jpg', 'corner': '',
         'cover': '', 'desc': '', 'url': '', 'rec_reason': '', 'danmaku': 153, 'biz_data': None, 'is_charge_video': 0,
         'vt': 0, 'enable_vt': 0, 'vt_display': '', 'subtitle': '', 'episode_count_text': '', 'release_status': 0,
         'is_intervene': 0, 'area': 0, 'style': 0, 'cate_name': '', 'is_live_room_inline': 0, 'live_status': 0,
         'live_time': '', 'online': 0, 'rank_index': 16, 'rank_offset': 16, 'roomid': 0, 'short_id': 0, 'spread_id': 0,
         'tags': '', 'uface': '', 'uid': 0, 'uname': '', 'user_cover': '', 'parent_area_id': 0, 'parent_area_name': '',
         'watched_show': None},
        {'type': 'video', 'id': 826984653, 'author': 'ChatGLM', 'mid': 3493270982232856, 'typeid': '231',
         'typename': '计算机技术', 'arcurl': 'http://www.bilibili.com/video/av826984653', 'aid': 826984653,
         'bvid': 'BV1iu4y1Z7bv',
         'title': '【报告】从GLM-130B到<em class="keyword">ChatGLM</em>：<em class="keyword">大模型</em>预训练与微调',
         'description': '本报告为GLM技术团队成员在「NLG专委会真知论坛（GenTalk第7期）」的报告分享，报告中详细讲述了GLM-130B预训练过程，以及ChatGLM开发过程，并提出了几点大模型开发心得。\n\n本论坛另有复旦大学MOSS团队成员孙天祥的相关报告，可参考：https://www.bilibili.com/video/BV1is4y1i7cZ',
         'arcrank': '0', 'pic': '//i0.hdslb.com/bfs/archive/d1df889d21c3da487c21930e10aea8a72a67b3c5.jpg',
         'play': 60841, 'video_review': 66, 'favorites': 3934, 'tag': '大模型,GLM,预训练,科技猎手2023,chatglm',
         'review': 156, 'pubdate': 1685807653, 'senddate': 1685823811, 'duration': '76:54', 'badgepay': False,
         'hit_columns': ['title', 'description', 'author', 'tag'], 'view_type': '', 'is_pay': 0, 'is_union_video': 0,
         'rec_tags': None, 'new_rec_tags': [], 'rank_score': 101780655, 'like': 1587,
         'upic': 'https://i1.hdslb.com/bfs/face/ed1c8faa182cd66788af5b988d78570bdcee0780.jpg', 'corner': '',
         'cover': '', 'desc': '', 'url': '', 'rec_reason': '', 'danmaku': 66, 'biz_data': None, 'is_charge_video': 0,
         'vt': 0, 'enable_vt': 0, 'vt_display': '', 'subtitle': '', 'episode_count_text': '', 'release_status': 0,
         'is_intervene': 0, 'area': 0, 'style': 0, 'cate_name': '', 'is_live_room_inline': 0, 'live_status': 0,
         'live_time': '', 'online': 0, 'rank_index': 17, 'rank_offset': 17, 'roomid': 0, 'short_id': 0, 'spread_id': 0,
         'tags': '', 'uface': '', 'uid': 0, 'uname': '', 'user_cover': '', 'parent_area_id': 0, 'parent_area_name': '',
         'watched_show': None},
        {'type': 'video', 'id': 1051768122, 'author': 'frontEndBugMaker', 'mid': 429914741, 'typeid': '231',
         'typename': '计算机技术', 'arcurl': 'http://www.bilibili.com/video/av1051768122', 'aid': 1051768122,
         'bvid': 'BV1UH4y1W7PH',
         'title': '【保姆级教程】使用<em class="keyword">ChatGLM3</em>-<em class="keyword">6B</em>＋oneAPI＋Fastgpt＋LLaMA-Factory实现本地<em class="keyword">大模型</em>微调＋知识库＋接口管理',
         'description': '使用了清华开源的大模型chatGLM3-6b进行本地部署，LLaMA-Factory进行大模型微调，使用fastgpt的知识库连接本地大模型，使用oneAPI进行接口管理。',
         'arcrank': '0', 'pic': '//i0.hdslb.com/bfs/archive/a348a89ce71340947aed7d06f88fc7f0a939f04e.jpg',
         'play': 14331, 'video_review': 8, 'favorites': 1158,
         'tag': '教程,模型,微调,编程开发,保姆级教程,知识库,本地搭建大模型', 'review': 175, 'pubdate': 1710672312,
         'senddate': 1710728461, 'duration': '74:19', 'badgepay': False, 'hit_columns': ['title', 'description', 'tag'],
         'view_type': '', 'is_pay': 0, 'is_union_video': 0, 'rec_tags': None, 'new_rec_tags': [],
         'rank_score': 101719297, 'like': 373,
         'upic': 'https://i2.hdslb.com/bfs/face/d3c13a4fbd1dfae11c054456d96314b63c83b0a7.jpg', 'corner': '',
         'cover': '', 'desc': '', 'url': '', 'rec_reason': '', 'danmaku': 8, 'biz_data': None, 'is_charge_video': 0,
         'vt': 0, 'enable_vt': 0, 'vt_display': '', 'subtitle': '', 'episode_count_text': '', 'release_status': 0,
         'is_intervene': 0, 'area': 0, 'style': 0, 'cate_name': '', 'is_live_room_inline': 0, 'live_status': 0,
         'live_time': '', 'online': 0, 'rank_index': 18, 'rank_offset': 18, 'roomid': 0, 'short_id': 0, 'spread_id': 0,
         'tags': '', 'uface': '', 'uid': 0, 'uname': '', 'user_cover': '', 'parent_area_id': 0, 'parent_area_name': '',
         'watched_show': None},
        {'type': 'video', 'id': 113049478432847, 'author': '吴恩达-机器学习', 'mid': 3546736138128063, 'typeid': '231',
         'typename': '计算机技术', 'arcurl': 'http://www.bilibili.com/video/av113049478432847', 'aid': 113049478432847,
         'bvid': 'BV15LH5e1EDQ',
         'title': '【保姆级教程】6小时掌握开源<em class="keyword">大模型</em>本地部署到微调，从硬件指南到<em class="keyword">ChatGLM3</em>-<em class="keyword">6B模型</em>部署微调实战，这应该是B站最好的<em class="keyword">大模型</em>教程了！',
         'description': '想领取超详细课件的伙伴，后台滴滴免费领取，更多与ChatGLM3及大模型相关的问题，欢迎评论区交流哦[打call]~',
         'arcrank': '0', 'pic': '//i1.hdslb.com/bfs/archive/14516528a708b212fc9d03759618ef3c9db4f933.png', 'play': 1410,
         'video_review': 21, 'favorites': 107,
         'tag': '人工智能,AI,科技是第一生产力,计算机视觉,深度学习,计算机技术,大模型,科技猎手,AIGC,大模型微调,大模型面试',
         'review': 1, 'pubdate': 1724998337, 'senddate': 1726630249, 'duration': '369:14', 'badgepay': False,
         'hit_columns': ['title', 'description', 'author', 'tag'], 'view_type': '', 'is_pay': 0, 'is_union_video': 0,
         'rec_tags': None, 'new_rec_tags': [], 'rank_score': 101687121, 'like': 23,
         'upic': 'https://i0.hdslb.com/bfs/face/86d6e918ae76c33dbbad2409ed442cb9aff3746b.jpg', 'corner': '',
         'cover': '', 'desc': '', 'url': '', 'rec_reason': '', 'danmaku': 21, 'biz_data': None, 'is_charge_video': 0,
         'vt': 0, 'enable_vt': 0, 'vt_display': '', 'subtitle': '', 'episode_count_text': '', 'release_status': 0,
         'is_intervene': 0, 'area': 0, 'style': 0, 'cate_name': '', 'is_live_room_inline': 0, 'live_status': 0,
         'live_time': '', 'online': 0, 'rank_index': 19, 'rank_offset': 19, 'roomid': 0, 'short_id': 0, 'spread_id': 0,
         'tags': '', 'uface': '', 'uid': 0, 'uname': '', 'user_cover': '', 'parent_area_id': 0, 'parent_area_name': '',
         'watched_show': None},
        {'type': 'video', 'id': 743207011, 'author': '人工智能与Python', 'mid': 1350253317, 'typeid': '231',
         'typename': '计算机技术', 'arcurl': 'http://www.bilibili.com/video/av743207011', 'aid': 743207011,
         'bvid': 'BV15k4y1P7N5',
         'title': '吹爆！全网最通俗易懂的<em class="keyword">ChatGLM</em>预训练+微调教程，北大博士后手把手带你调用属于自己的对话<em class="keyword">大模型</em>—<em class="keyword">ChatGLM</em>!',
         'description': '关注公众号：咕泡AI，回复：555\r\n即可获取课程资料及60G深度学习精选资料包！\r\n更有：AI公开课、论文指导、简历指导、竞赛指导、技术问题解答！\r\n1.上千篇CVPR、ICCV顶会论文\r\n2.动手学习深度学习、花书、西瓜书等AI必读书籍\r\n3.唐宇迪博士精心整理的人工智能学习大纲\r\n4.机器学习算法+深度学习神经网络基础教程\r\n5.OpenCV、Pytorch、YOLO等主流框架算法实战教程',
         'arcrank': '0', 'pic': '//i0.hdslb.com/bfs/archive/01903bb8df3eedfe57feef07e52849f35f1d77f5.png',
         'play': 10891, 'video_review': 47, 'favorites': 621,
         'tag': '人工智能,机器学习,深度学习,自然语言处理,大模型,多模态,ChatGLM-6B,ChatGLM微调,ChatGLM训练,ChatGLM部署',
         'review': 21, 'pubdate': 1688723464, 'senddate': 1688811833, 'duration': '178:50', 'badgepay': False,
         'hit_columns': ['title', 'description', 'tag'], 'view_type': '', 'is_pay': 0, 'is_union_video': 0,
         'rec_tags': None, 'new_rec_tags': [], 'rank_score': 101667211, 'like': 111,
         'upic': 'https://i0.hdslb.com/bfs/face/fad84c271423850eace9745a417f613b38fc2bbb.jpg', 'corner': '',
         'cover': '', 'desc': '', 'url': '', 'rec_reason': '', 'danmaku': 47, 'biz_data': None, 'is_charge_video': 0,
         'vt': 0, 'enable_vt': 0, 'vt_display': '', 'subtitle': '', 'episode_count_text': '', 'release_status': 0,
         'is_intervene': 0, 'area': 0, 'style': 0, 'cate_name': '', 'is_live_room_inline': 0, 'live_status': 0,
         'live_time': '', 'online': 0, 'rank_index': 20, 'rank_offset': 20, 'roomid': 0, 'short_id': 0, 'spread_id': 0,
         'tags': '', 'uface': '', 'uid': 0, 'uname': '', 'user_cover': '', 'parent_area_id': 0, 'parent_area_name': '',
         'watched_show': None}]}]

for result in raw:
    if result['data']:  # 检查data列表是否非空
        for item in result['data']:
            processed_data = [
             item.get('type', '未知类型'),
             item.get('author', '未知作者'),
             item.get('typename', '未知分类'),
             item.get('arcurl', '无链接'),
             item.get('title', '无标题').replace('<em class="keyword">', '').replace('</em>', ''),
             item.get('description', '无描述'),
             item.get('play', 0),
             item.get('video_review', 0),
             item.get('favorites', 0),
             item.get('comment', 0),
             # comments,
             # datetime.datetime.fromtimestamp(item.get('pubdate', 0)).strftime('%Y-%m-%d %H:%M:%S'),
            ]

            headers = ["类型", "作者", "分类", "视频链接", "标题", "描述", "播放量", "弹幕数", "收藏数", "标签",
                       "发布日期", "评论"]

            result_text = '\n'.join(f"{header}: {data}" for header, data in zip(headers, processed_data))

            print(result_text)